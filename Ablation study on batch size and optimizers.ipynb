{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"01617dae0b7647ff991231fc7d4302ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"018a325d68c5472593552fe66703b616":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04635cace54c4c3c9ecc733ebcc438de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f44169ff3e047d9b5feed269e173dd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1079402f13b2433fa87a6a9e932594c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142ca26ae20a42388f5e20916cea4761":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1480f81dcd1c4a42947319c1c07363b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15646e54c2a54ac0a2d6e122bbb83fbf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16d7bc410cbe46b9bac373fb3c57f25f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4820d43186e340b0bcfab188e939d9da","placeholder":"​","style":"IPY_MODEL_184fbe81f2154dceb2880deeb7719e57","value":" 380/380 [02:43&lt;00:00,  2.42it/s]"}},"1790bd950ebe451eb82c76e245d52418":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"184fbe81f2154dceb2880deeb7719e57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a34009b9bcc43508a74d4ca9adee005":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c10933f63e5487fbd99020534897cf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_686c85d9fb3a401993daa2aff7e6afd5","IPY_MODEL_87feb57d1f4b4dc0b5894abbb87db6e6","IPY_MODEL_343c0c802076464cb1daa07141fef5f8","IPY_MODEL_4e5fae5068484896a73fc741e2b7be7f"],"layout":"IPY_MODEL_d4985e9da642420d84ad31fcf1e12de5"}},"1d1f053b134446d49439dcac4e936a69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1df470e36c0c4ee7bbef758875c6bc27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f53ebf0e0a347198a3d282879744226":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6794d7fe0c1c47f5b75f1fdeed8e9dda","max":380,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1df470e36c0c4ee7bbef758875c6bc27","value":380}},"25c117dc79a84e969c37f5c26c2f3013":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"270d759fe1904101bf6576c370363b96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39c294bf06904032911dd40d8d264cc5","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d823811d5ca4e0ca22450d872fe4467","value":1000}},"2752582348a54d978a6b411af8d7ffca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"277b352e19de41c58fc51c15a0c18dc1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2abe0ecda64d48f899eee1ae56be2f7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b21db5cee72049cba95c1211fbd0efae","IPY_MODEL_5cd86ffbc6c2407ba86c8401d38700f8","IPY_MODEL_3621eba9e42543ca80cd548f525bdee5"],"layout":"IPY_MODEL_5c799a6daca3416fb9d6a9bb5534c486"}},"2ed0fb244d0d48379f164ebcf5b9368d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15646e54c2a54ac0a2d6e122bbb83fbf","placeholder":"​","style":"IPY_MODEL_f9744ee7542849d09eca2199042bf828","value":"id2label.json: 100%"}},"2fb6cf1d29ac4cfb87cfd29343b36025":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31524db81ee240fd830c437d95e48c23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"340329f664a547cd81cf8ba256aaf482":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"343c0c802076464cb1daa07141fef5f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d764235f788482e8ad290825ec66e53","placeholder":"​","style":"IPY_MODEL_aaff3c510f9f48fe976da60123cd337c","value":"Your token has been saved to /root/.cache/huggingface/token"}},"3621eba9e42543ca80cd548f525bdee5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eac91c8db5a54e8cb434be22f6942dbf","placeholder":"​","style":"IPY_MODEL_e009f2ee46fc4326bc4020cafff7f941","value":" 82.5k/82.5k [00:00&lt;00:00, 2.42MB/s]"}},"38293dc2747b4ec18ff981181fb978cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39c294bf06904032911dd40d8d264cc5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eea9c2d0b624b35a7ebdc6955317fd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f09061fb56b416ca8ee50a9ee4c8d28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b08c48ea491043c6b123ca02ce1d398f","placeholder":"​","style":"IPY_MODEL_d65788532d294420812f5b02fb076c1f","value":"dataset_infos.json: 100%"}},"46560630018f48baa5f21d9385d860fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46ef40bd54e743038a2616fe314befce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47556373d2d645bba072e2cc9c01b1c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4820d43186e340b0bcfab188e939d9da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"488221d4f67c43f49a263e6bc20c6a55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46560630018f48baa5f21d9385d860fc","placeholder":"​","style":"IPY_MODEL_a94cd2cdc3754720a1545bcc436c9b69","value":" 324M/324M [00:02&lt;00:00, 174MB/s]"}},"48bd74d6f72241c68d68307fec652db5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4afe454c0dd74d819d15900f4bd04231":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01617dae0b7647ff991231fc7d4302ca","placeholder":"​","style":"IPY_MODEL_51062b719e2447cbb66f417fec6ed3b9","value":"100%"}},"4bd987ea76524ba19a8c33b0ca87e3f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1e88192495a4f68b2c88b66b07cdd12","IPY_MODEL_79116c4298324e778a91fc9b5a2ac65b","IPY_MODEL_ba35e93b2fee41e59858fe1b09cee62a"],"layout":"IPY_MODEL_5830a4ba350f407e949cb4c3df2e8cd6"}},"4c1565ae217b4853b51979f603c427ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f44169ff3e047d9b5feed269e173dd5","placeholder":"​","style":"IPY_MODEL_fd91de21f1b64f71aeb6950d1968e152","value":"100%"}},"4d9cc4d9b4af4e0889f4797f6fba05f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c1565ae217b4853b51979f603c427ae","IPY_MODEL_1f53ebf0e0a347198a3d282879744226","IPY_MODEL_16d7bc410cbe46b9bac373fb3c57f25f"],"layout":"IPY_MODEL_48bd74d6f72241c68d68307fec652db5"}},"4e5fae5068484896a73fc741e2b7be7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f357cad809ab4bfe88fad92b97f92fd2","placeholder":"​","style":"IPY_MODEL_7391a69eff5b42839b97435d53677fe2","value":"Login successful"}},"51062b719e2447cbb66f417fec6ed3b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52f51e7e8ff44a0a9e72655539ccdb4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4087fc90faf48e3b2203b22d54ae372","placeholder":"​","style":"IPY_MODEL_7727703b3d08479ebc45eb78e26cca35","value":" 866M/866M [00:14&lt;00:00, 85.6MB/s]"}},"54bf5459287444c6916357602ff3f36a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5692d20456044bf696688fbab86a1052":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56a413738aef4fcbbd081d21b53cfc5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5830a4ba350f407e949cb4c3df2e8cd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59b11982ce384595a6ff6c2d5a7eaa13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c32db16c9394eaca2a84717e7c85222":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f83a210bd6f402a850955d9c2ef35a0","max":635,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93a1b3c7dd784dd69eebf273ba626667","value":635}},"5c799a6daca3416fb9d6a9bb5534c486":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cd86ffbc6c2407ba86c8401d38700f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82cb045136a7447ea8b2f3ee74b3b219","max":82540,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38293dc2747b4ec18ff981181fb978cc","value":82540}},"5f55d724f9fa497487534761f4e808a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60280ba74d8b4940a7dc4df2e9f71415":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6099fc437b9543048bc925bc9e13f818":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63dc488a8d0d4d3eba7afc05032f4b3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f84b103ca49415882b375ce985d35f0","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59b11982ce384595a6ff6c2d5a7eaa13","value":6}},"6598da2801324d7ea5ea1c84285b66e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ed0fb244d0d48379f164ebcf5b9368d","IPY_MODEL_e9bbce38a51f44069e2b828239441899","IPY_MODEL_c16947ce20884931962e892046767579"],"layout":"IPY_MODEL_60280ba74d8b4940a7dc4df2e9f71415"}},"6794d7fe0c1c47f5b75f1fdeed8e9dda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68023198f381435a93fcad2ce078b2e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac48ddd1d88e4f45a4b506690c4e0f8c","placeholder":"​","style":"IPY_MODEL_1790bd950ebe451eb82c76e245d52418","value":" 1000/1000 [00:01&lt;00:00, 708.63 examples/s]"}},"686c85d9fb3a401993daa2aff7e6afd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69d0bd2157924512926b65456d4db23d","placeholder":"​","style":"IPY_MODEL_1480f81dcd1c4a42947319c1c07363b4","value":"Token is valid (permission: write)."}},"68bdd452bed845cfb88d652bb443604a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68d1ebd789674373b2dc2709c50254e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"696a6444758044a1aabd5ae25021ffd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56a413738aef4fcbbd081d21b53cfc5f","placeholder":"​","style":"IPY_MODEL_04635cace54c4c3c9ecc733ebcc438de","value":"Generating train split: 100%"}},"69d0bd2157924512926b65456d4db23d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bab45e4b3f24a8aa69df627cbbea575":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1079402f13b2433fa87a6a9e932594c0","placeholder":"​","style":"IPY_MODEL_47556373d2d645bba072e2cc9c01b1c6","value":" 4.26k/4.26k [00:00&lt;00:00, 138kB/s]"}},"6fc70f55a8f447e2939e1ed638df80c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_740c0ab7d00a4f0ea4a33683d3713d00","IPY_MODEL_d0962cfcae454d48823b20834aa7645c","IPY_MODEL_6bab45e4b3f24a8aa69df627cbbea575"],"layout":"IPY_MODEL_5692d20456044bf696688fbab86a1052"}},"7391a69eff5b42839b97435d53677fe2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"740c0ab7d00a4f0ea4a33683d3713d00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ceee8d6a76e7430eaa88f3cf26652f22","placeholder":"​","style":"IPY_MODEL_8e3deea9b35b4139bb2b7d001adcee86","value":"README.md: 100%"}},"746e2e69ac464b0c87cc388e5d22ded7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7727703b3d08479ebc45eb78e26cca35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7903e283086043fb9a66a3c7b00ffb04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee3e3bb6219a49aabb6bf5350783bb4f","IPY_MODEL_63dc488a8d0d4d3eba7afc05032f4b3c","IPY_MODEL_7b3129a6c87f46eb9ebc14c3e87d39cf"],"layout":"IPY_MODEL_b3ea2b6e22574d84a1f3f69eee2b32fa"}},"79116c4298324e778a91fc9b5a2ac65b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_746e2e69ac464b0c87cc388e5d22ded7","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce68f1410412405c9578e4d80814228a","value":6}},"7b3129a6c87f46eb9ebc14c3e87d39cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abcd30b56a6d4b90a38c333d92406381","placeholder":"​","style":"IPY_MODEL_ebf48db6bf844516a8a1e335c11f3db3","value":" 6/20 [01:58&lt;04:35, 19.67s/it]"}},"7d764235f788482e8ad290825ec66e53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f84b103ca49415882b375ce985d35f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8095ef3b177742c2bcf438484620e04f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_696a6444758044a1aabd5ae25021ffd5","IPY_MODEL_270d759fe1904101bf6576c370363b96","IPY_MODEL_68023198f381435a93fcad2ce078b2e2"],"layout":"IPY_MODEL_9d0882a2cfa94182b620ac2d0e6f1c3d"}},"80fd0eb8606c41e796419aea5f9efc1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82cb045136a7447ea8b2f3ee74b3b219":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83bfb79ef0464b9c937d18ba4dc8a40a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8781867aca33479faafb06889b9cae54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87b417f7a835472285fcb95c0b127b70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87feb57d1f4b4dc0b5894abbb87db6e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_932f7e39e62e4dc99cdca1875ce795c6","placeholder":"​","style":"IPY_MODEL_142ca26ae20a42388f5e20916cea4761","value":"Your token has been saved in your configured git credential helpers (store)."}},"8991f225eb754b11a1b056a55fc2da84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a4848c0ce90421c86fd00dea92716e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a90194ec5044a00ab933ac788c2ce97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68d1ebd789674373b2dc2709c50254e1","max":866052064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96d217af725c4ffa97f7846cf1576d03","value":866052064}},"8d7dbc32a0ad40ad95086fa8dbd47ed2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f09061fb56b416ca8ee50a9ee4c8d28","IPY_MODEL_5c32db16c9394eaca2a84717e7c85222","IPY_MODEL_d3572729408f4cf283b8ea11bfa1dfaa"],"layout":"IPY_MODEL_cfc9ee58e23c469ca0436e0ddcb3957e"}},"8df418c659084100b76130ce6dde86e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d1f053b134446d49439dcac4e936a69","max":324302379,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8781867aca33479faafb06889b9cae54","value":324302379}},"8e3deea9b35b4139bb2b7d001adcee86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"932f7e39e62e4dc99cdca1875ce795c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93a1b3c7dd784dd69eebf273ba626667":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96d217af725c4ffa97f7846cf1576d03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97867c3e4e5e47ef96fe1a2644fdf246":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"990df94ce43a499fbba4d937f9889c13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25c117dc79a84e969c37f5c26c2f3013","max":538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3eea9c2d0b624b35a7ebdc6955317fd1","value":538}},"9d0882a2cfa94182b620ac2d0e6f1c3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d823811d5ca4e0ca22450d872fe4467":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9dad9cbd81d24086bc0cef4ed42e07b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83bfb79ef0464b9c937d18ba4dc8a40a","placeholder":"​","style":"IPY_MODEL_5f55d724f9fa497487534761f4e808a7","value":"train-00000-of-00001.parquet: 100%"}},"9f83a210bd6f402a850955d9c2ef35a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1d299215b7c4e6a8be05a6ad6d3ebb9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4087fc90faf48e3b2203b22d54ae372":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a560d89bb5b747ea8d6d7339ebf996cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f197268b4a7b49a28c0150d97ae00c2c","placeholder":"​","style":"IPY_MODEL_2752582348a54d978a6b411af8d7ffca","value":"preprocessor_config.json: 100%"}},"a8cfcc83ea4d4c3e8c0eb40d345d605d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fde783dc2fcc4cf5848a8d6fd9f2060b","IPY_MODEL_8a90194ec5044a00ab933ac788c2ce97","IPY_MODEL_52f51e7e8ff44a0a9e72655539ccdb4f"],"layout":"IPY_MODEL_c2ff48c2b6ec47c89d1465b0103fddce"}},"a94cd2cdc3754720a1545bcc436c9b69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aaff3c510f9f48fe976da60123cd337c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abcd30b56a6d4b90a38c333d92406381":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac48ddd1d88e4f45a4b506690c4e0f8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad21c824c27e403db7f3c2f03706dc8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af86b03ee63f47d99dcba2c2d5f87a43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b08c48ea491043c6b123ca02ce1d398f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b21db5cee72049cba95c1211fbd0efae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5219deca99c438fb9d440b1c701597c","placeholder":"​","style":"IPY_MODEL_80fd0eb8606c41e796419aea5f9efc1c","value":"config.json: 100%"}},"b3ea2b6e22574d84a1f3f69eee2b32fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5a5f21a612143a1b07322eb2883aaf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4afe454c0dd74d819d15900f4bd04231","IPY_MODEL_e8f73e63bf8a4822af43c33ead93649b","IPY_MODEL_e1905b6d2665450b8c89f05a582b299f"],"layout":"IPY_MODEL_277b352e19de41c58fc51c15a0c18dc1"}},"b739f86a36064c3c96626f1276359ae2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba35e93b2fee41e59858fe1b09cee62a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad21c824c27e403db7f3c2f03706dc8e","placeholder":"​","style":"IPY_MODEL_97867c3e4e5e47ef96fe1a2644fdf246","value":" 6/20 [01:52&lt;04:23, 18.81s/it]"}},"bce506b6be854ed5ad405ce29bbed051":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfc76c2fb92d4959b21a55121efc1f7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c16947ce20884931962e892046767579":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7abebb518d248fbb7e573bca72c2aba","placeholder":"​","style":"IPY_MODEL_8a4848c0ce90421c86fd00dea92716e5","value":" 852/852 [00:00&lt;00:00, 63.2kB/s]"}},"c19fca2497d24cfeb7ddf74d9d94a621":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2ff48c2b6ec47c89d1465b0103fddce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7abebb518d248fbb7e573bca72c2aba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb4d178f4c8d47bbb8d5f653c0ee6077":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdc0ede841c44b14a60ff8969af87740":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a560d89bb5b747ea8d6d7339ebf996cd","IPY_MODEL_990df94ce43a499fbba4d937f9889c13","IPY_MODEL_d6ad45ae8306476b868cde1e49f5f42c"],"layout":"IPY_MODEL_af86b03ee63f47d99dcba2c2d5f87a43"}},"ce68f1410412405c9578e4d80814228a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ceee8d6a76e7430eaa88f3cf26652f22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfc9ee58e23c469ca0436e0ddcb3957e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0962cfcae454d48823b20834aa7645c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb4d178f4c8d47bbb8d5f653c0ee6077","max":4257,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fb6cf1d29ac4cfb87cfd29343b36025","value":4257}},"d3572729408f4cf283b8ea11bfa1dfaa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6345a61667d454db2f764253ccdfd7e","placeholder":"​","style":"IPY_MODEL_bfc76c2fb92d4959b21a55121efc1f7a","value":" 635/635 [00:00&lt;00:00, 43.5kB/s]"}},"d4985e9da642420d84ad31fcf1e12de5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"d5219deca99c438fb9d440b1c701597c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6345a61667d454db2f764253ccdfd7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d65788532d294420812f5b02fb076c1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6ad45ae8306476b868cde1e49f5f42c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1d299215b7c4e6a8be05a6ad6d3ebb9","placeholder":"​","style":"IPY_MODEL_31524db81ee240fd830c437d95e48c23","value":" 538/538 [00:00&lt;00:00, 13.1kB/s]"}},"d9527593775745afac48a438cd11c7e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e009f2ee46fc4326bc4020cafff7f941":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1905b6d2665450b8c89f05a582b299f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c19fca2497d24cfeb7ddf74d9d94a621","placeholder":"​","style":"IPY_MODEL_68bdd452bed845cfb88d652bb443604a","value":" 380/380 [02:48&lt;00:00,  2.34it/s]"}},"e1e88192495a4f68b2c88b66b07cdd12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9527593775745afac48a438cd11c7e0","placeholder":"​","style":"IPY_MODEL_6099fc437b9543048bc925bc9e13f818","value":" 30%"}},"e8f73e63bf8a4822af43c33ead93649b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87b417f7a835472285fcb95c0b127b70","max":380,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b739f86a36064c3c96626f1276359ae2","value":380}},"e9bbce38a51f44069e2b828239441899":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_340329f664a547cd81cf8ba256aaf482","max":852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_018a325d68c5472593552fe66703b616","value":852}},"eac91c8db5a54e8cb434be22f6942dbf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebf48db6bf844516a8a1e335c11f3db3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec68acd0ebde42e4be05d8896533e153":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9dad9cbd81d24086bc0cef4ed42e07b3","IPY_MODEL_8df418c659084100b76130ce6dde86e7","IPY_MODEL_488221d4f67c43f49a263e6bc20c6a55"],"layout":"IPY_MODEL_46ef40bd54e743038a2616fe314befce"}},"ee3e3bb6219a49aabb6bf5350783bb4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8991f225eb754b11a1b056a55fc2da84","placeholder":"​","style":"IPY_MODEL_bce506b6be854ed5ad405ce29bbed051","value":" 30%"}},"f197268b4a7b49a28c0150d97ae00c2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f357cad809ab4bfe88fad92b97f92fd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9744ee7542849d09eca2199042bf828":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd91de21f1b64f71aeb6950d1968e152":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fde783dc2fcc4cf5848a8d6fd9f2060b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a34009b9bcc43508a74d4ca9adee005","placeholder":"​","style":"IPY_MODEL_54bf5459287444c6916357602ff3f36a","value":"model.safetensors: 100%"}}}},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86142,"databundleVersionId":9786425,"sourceType":"competition"},{"sourceId":9591262,"sourceType":"datasetVersion","datasetId":5849841},{"sourceId":9595174,"sourceType":"datasetVersion","datasetId":5852933},{"sourceId":9608018,"sourceType":"datasetVersion","datasetId":5862357}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport json\nimport os\n\n\nclass Label:\n    def __init__(self, name, id, csId, csTrainId, level4id, level3Id, category, level2Id, level1Id, hasInstances, ignoreInEval, color):\n        self.name = name\n        self.id = id\n        self.csId = csId\n        self.csTrainId = csTrainId\n        self.level4id = level4id\n        self.level3Id = level3Id\n        self.category = category\n        self.level2Id = level2Id\n        self.level1Id = level1Id\n        self.hasInstances = hasInstances\n        self.ignoreInEval = ignoreInEval\n        self.color = color\n\nlabels_details = [\n    #       name                     id    csId     csTrainId level4id        level3Id  category           level2Id      level1Id  hasInstances   ignoreInEval   color\n    Label(  'road'                 ,  0   ,  7 ,     0 ,       0   ,     0  ,   'drivable'            , 0           , 0      , False        , False        , (128, 64,128)  ),\n    Label(  'parking'              ,  1   ,  9 ,   255 ,       1   ,     1  ,   'drivable'            , 1           , 0      , False        , False         , (250,170,160)  ),\n    Label(  'drivable fallback'    ,  2   ,  255 ,   255 ,     2   ,       1  ,   'drivable'            , 1           , 0      , False        , False         , ( 81,  0, 81)  ),\n    Label(  'sidewalk'             ,  3   ,  8 ,     1 ,       3   ,     2  ,   'non-drivable'        , 2           , 1      , False        , False        , (244, 35,232)  ),\n    Label(  'rail track'           ,  4   , 10 ,   255 ,       3   ,     3  ,   'non-drivable'        , 3           , 1      , False        , False         , (230,150,140)  ),\n    Label(  'non-drivable fallback',  5   , 255 ,     9 ,      4   ,      3  ,   'non-drivable'        , 3           , 1      , False        , False        , (152,251,152)  ),\n    Label(  'person'               ,  6   , 24 ,    11 ,       5   ,     4  ,   'living-thing'        , 4           , 2      , True         , False        , (220, 20, 60)  ),\n    Label(  'animal'               ,  7   , 255 ,   255 ,      6   ,      4  ,   'living-thing'        , 4           , 2      , True         , True        , (246, 198, 145)),\n    Label(  'rider'                ,  8   , 25 ,    12 ,       7   ,     5  ,   'living-thing'        , 5           , 2      , True         , False        , (255,  0,  0)  ),\n    Label(  'motorcycle'           ,  9   , 32 ,    17 ,       8   ,     6  ,   '2-wheeler'           , 6           , 3      , True         , False        , (  0,  0,230)  ),\n    Label(  'bicycle'              , 10   , 33 ,    18 ,       9   ,     7  ,   '2-wheeler'           , 6           , 3      , True         , False        , (119, 11, 32)  ),\n    Label(  'autorickshaw'         , 11   , 255 ,   255 ,     10   ,      8  ,   'autorickshaw'        , 7           , 3      , True         , False        , (255, 204, 54) ),\n    Label(  'car'                  , 12   , 26 ,    13 ,      11   ,     9  ,   'car'                 , 7           , 3      , True         , False        , (  0,  0,142)  ),\n    Label(  'truck'                , 13   , 27 ,    14 ,      12   ,     10 ,   'large-vehicle'       , 8           , 3      , True         , False        , (  0,  0, 70)  ),\n    Label(  'bus'                  , 14   , 28 ,    15 ,      13   ,     11 ,   'large-vehicle'       , 8           , 3      , True         , False        , (  0, 60,100)  ),\n    Label(  'caravan'              , 15   , 29 ,   255 ,      14   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True         , (  0,  0, 90)  ),\n    Label(  'trailer'              , 16   , 30 ,   255 ,      15   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True         , (  0,  0,110)  ),\n    Label(  'train'                , 17   , 31 ,    16 ,      15   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True        , (  0, 80,100)  ),\n    Label(  'vehicle fallback'     , 18   , 355 ,   255 ,     15   ,      12 ,   'large-vehicle'       , 8           , 3      , True         , False        , (136, 143, 153)),\n    Label(  'curb'                 , 19   ,255 ,   255 ,      16   ,     13 ,   'barrier'             , 9           , 4      , False        , False        , (220, 190, 40)),\n    Label(  'wall'                 , 20   , 12 ,     3 ,      17   ,     14 ,   'barrier'             , 9           , 4      , False        , False        , (102,102,156)  ),\n    Label(  'fence'                , 21   , 13 ,     4 ,      18   ,     15 ,   'barrier'             , 10           , 4      , False        , False        , (190,153,153)  ),\n    Label(  'guard rail'           , 22   , 14 ,   255 ,      19   ,     16 ,   'barrier'             , 10          , 4      , False        , False         , (180,165,180)  ),\n    Label(  'billboard'            , 23   , 255 ,   255 ,     20   ,      17 ,   'structures'          , 11           , 4      , False        , False        , (174, 64, 67) ),\n    Label(  'traffic sign'         , 24   , 20 ,     7 ,      21   ,     18 ,   'structures'          , 11          , 4      , False        , False        , (220,220,  0)  ),\n    Label(  'traffic light'        , 25   , 19 ,     6 ,      22   ,     19 ,   'structures'          , 11          , 4      , False        , False        , (250,170, 30)  ),\n    Label(  'pole'                 , 26   , 17 ,     5 ,      23   ,     20 ,   'structures'          , 12          , 4      , False        , False        , (153,153,153)  ),\n    Label(  'polegroup'            , 27   , 18 ,   255 ,      23   ,     20 ,   'structures'          , 12          , 4      , False        , False         , (153,153,153)  ),\n    Label(  'obs-str-bar-fallback' , 28   , 255 ,   255 ,     24   ,      21 ,   'structures'          , 12          , 4      , False        , False        , (169, 187, 214) ),\n    Label(  'building'             , 29   , 11 ,     2 ,      25   ,     22 ,   'construction'        , 13          , 5      , False        , False        , ( 70, 70, 70)  ),\n    Label(  'bridge'               , 30   , 15 ,   255 ,      26   ,     23 ,   'construction'        , 13          , 5      , False        , False         , (150,100,100)  ),\n    Label(  'tunnel'               , 31   , 16 ,   255 ,      26   ,     23 ,   'construction'        , 13          , 5      , False        , False         , (150,120, 90)  ),\n    Label(  'vegetation'           , 32   , 21 ,     8 ,      27   ,     24 ,   'vegetation'          , 14          , 5      , False        , False        , (107,142, 35)  ),\n    Label(  'sky'                  , 33   , 23 ,    10 ,      28   ,     25 ,   'sky'                 , 15          , 6      , False        , False        , ( 70,130,180)  ),\n    Label(  'fallback background'  , 34   , 255 ,   255 ,     29   ,      25 ,   'object fallback'     , 15          , 6      , False        , False        , (169, 187, 214)),\n    Label(  'unlabeled'            , 35   ,  0  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n    Label(  'ego vehicle'          , 36   ,  1  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n    Label(  'rectification border' , 37   ,  2  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n    Label(  'out of roi'           , 38   ,  3  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n    Label(  'license plate'        , 39   , 255 ,     255 ,   255   ,      255 ,   'vehicle'             , 255         , 255    , False        , True         , (  0,  0,142)  ),\n\n]\n\n\n\n# Function to get label information from pixel color\ndef get_label_by_color(color):\n    for label in labels_details:\n        if label.color == tuple(color):  # Compare the pixel color to the label color\n            return label\n    return None\n\nimport torch\nimport numpy as np\n\n# Step 1: Build a dictionary to map color tuples to label IDs\ncolor_to_id_map = {tuple(label.color): label.id for label in labels_details}\nid_to_label_map = {int(label.id): label.name for label in labels_details}\ndef id_to_label_map():\n    new_dict = {}\n    for label in labels_details:\n        new_dict[int(label.id)] = label.name\n    return new_dict","metadata":{"id":"mxRgRfimOYQ1","execution":{"iopub.status.busy":"2024-11-03T08:33:20.56359Z","iopub.execute_input":"2024-11-03T08:33:20.563886Z","iopub.status.idle":"2024-11-03T08:33:25.107901Z","shell.execute_reply.started":"2024-11-03T08:33:20.563854Z","shell.execute_reply":"2024-11-03T08:33:25.106862Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"First, I ","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nlabels = [label.name for label in labels_details]\nlabels.append('ground')\nlabel_dict = {}\nlabel_dict = label_dict.fromkeys(labels, 0)\n# label_dict['ground'] = 0\nbase_dir = '/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset/labels' \nfor sub_dir in os.listdir(base_dir):\n    sub_dir_path = os.path.join(base_dir, sub_dir)\n\n    for json_file in os.listdir(sub_dir_path):\n        if json_file.endswith('_polygons.json'):\n            json_path = os.path.join(sub_dir_path, json_file)\n            with open(json_path, 'r') as f:\n                data = json.load(f)\n                unique_label = set()\n                for obj in data.get('objects', []):\n                    unique_label.add(obj.get('label'))\n                for s in unique_label:\n                    label_dict[s] += 1","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:36:48.806004Z","iopub.execute_input":"2024-11-03T08:36:48.807091Z","iopub.status.idle":"2024-11-03T08:38:12.565893Z","shell.execute_reply.started":"2024-11-03T08:36:48.80705Z","shell.execute_reply":"2024-11-03T08:38:12.564854Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import operator\nsorted_label_dict = dict(sorted(label_dict.items(),key = operator.itemgetter(1)))\nsorted_label_dict","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:38:12.567703Z","iopub.execute_input":"2024-11-03T08:38:12.568034Z","iopub.status.idle":"2024-11-03T08:38:12.576884Z","shell.execute_reply.started":"2024-11-03T08:38:12.568002Z","shell.execute_reply":"2024-11-03T08:38:12.575997Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Defining a threshold for lower freq labels which we will try to treat separately","metadata":{}},{"cell_type":"code","source":"lower_freq_labels = []\nfor i in sorted_label_dict:\n    if sorted_label_dict[i] < 100 and sorted_label_dict[i] > 4:\n        lower_freq_labels.append(i)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:38:12.577998Z","iopub.execute_input":"2024-11-03T08:38:12.578396Z","iopub.status.idle":"2024-11-03T08:38:12.588315Z","shell.execute_reply.started":"2024-11-03T08:38:12.578364Z","shell.execute_reply":"2024-11-03T08:38:12.587384Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\n\ndef extract_label_images(base_dir, class_name):\n    label_ids = []\n    \n    # Go through each sub-directory in the 'labels' folder\n    for sub_dir in os.listdir(base_dir):\n        sub_dir_path = os.path.join(base_dir, sub_dir)\n            \n        # Iterate through each file in the sub-directory\n        for json_file in os.listdir(sub_dir_path):\n            if json_file.endswith('_polygons.json'):\n                json_path = os.path.join(sub_dir_path, json_file)\n\n                # Load the JSON file\n                with open(json_path, 'r') as f:\n                    data = json.load(f)\n                    for obj in data.get('objects', []):\n                        if obj.get('label') == class_name:\n                            # Extract the unique image ID from the file name (e.g., 'frame0029')\n                            image_id = json_file.split('_')[0].replace('frame', '')\n                            image_id = sub_dir + \"_\" + image_id\n                            label_ids.append(image_id)\n                            break\n    \n    return label_ids\n\n\n# Example usage\nbase_dir = '/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset/labels' \n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:38:12.590586Z","iopub.execute_input":"2024-11-03T08:38:12.591035Z","iopub.status.idle":"2024-11-03T08:38:12.60089Z","shell.execute_reply.started":"2024-11-03T08:38:12.590992Z","shell.execute_reply":"2024-11-03T08:38:12.600117Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lower_freq_labels","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:38:12.602022Z","iopub.execute_input":"2024-11-03T08:38:12.602835Z","iopub.status.idle":"2024-11-03T08:38:12.616311Z","shell.execute_reply.started":"2024-11-03T08:38:12.602765Z","shell.execute_reply":"2024-11-03T08:38:12.61554Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lfreq_label_dict = {}\nlfreq_label_dict = lfreq_label_dict.fromkeys(lower_freq_labels, [])\nfor label in lfreq_label_dict:\n    ls = extract_label_images(base_dir, label)\n    lfreq_label_dict[label] = ls","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:38:12.619436Z","iopub.execute_input":"2024-11-03T08:38:12.619959Z","iopub.status.idle":"2024-11-03T08:44:37.611639Z","shell.execute_reply.started":"2024-11-03T08:38:12.619927Z","shell.execute_reply":"2024-11-03T08:44:37.610839Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for k, v in lfreq_label_dict.items():\n    print(k, \" \", len(v))","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:44:37.612855Z","iopub.execute_input":"2024-11-03T08:44:37.61359Z","iopub.status.idle":"2024-11-03T08:44:37.619064Z","shell.execute_reply.started":"2024-11-03T08:44:37.613544Z","shell.execute_reply":"2024-11-03T08:44:37.618105Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\ndef organize_images_by_class(class_labels, image_dir, output_dir):\n    \"\"\"Organizes images into subdirectories based on class labels and image IDs.\n\n    Args:\n        class_labels (dict): A dictionary where keys are class labels and values are lists of image IDs.\n        image_dir (str): The directory containing the original images.\n        output_dir (str): The root directory where class subdirectories will be created.\n    \"\"\"\n\n\n    for class_label, image_ids in class_labels.items():\n        class_subdir = os.path.join(output_dir, str(class_label))  # Creating subdir name\n\n        # Create subdirectory if it doesn't exist\n        os.makedirs(class_subdir, exist_ok=True)\n\n        for image_id_string in image_ids:\n            subdir, image_id = image_id_string.split(\"_\")\n\n            try:\n                image_name = f\"frame{image_id}_leftImg8bit.jpg\"\n                source_image_path = os.path.join(image_dir, subdir, image_name)\n                shutil.copy(source_image_path, os.path.join(class_subdir, image_name))\n                print(f\"Copied '{image_name}' to '{class_label}' subdirectory.\")\n\n\n            except FileNotFoundError:\n                try:\n                    image_name = f\"{image_id}_leftImg8bit.jpg\"\n                    source_image_path = os.path.join(image_dir, subdir, image_name)\n                    shutil.copy(source_image_path, os.path.join(class_subdir, image_name))\n                    print(f\"Copied '{image_name}' to '{class_label}' subdirectory.\")\n\n                except FileNotFoundError:\n                    print(f\"WARNING: Neither file pattern found for {image_id_string}\")\n\n\n# Example usage (replace with your actual data)\nclass_labels = lfreq_label_dict\n\nimage_dir = r\"/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset/train\"\noutput_dir = r\"/kaggle/working/images\"\n\n\norganize_images_by_class(class_labels, image_dir, output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:44:37.620474Z","iopub.execute_input":"2024-11-03T08:44:37.62114Z","iopub.status.idle":"2024-11-03T08:44:39.434383Z","shell.execute_reply.started":"2024-11-03T08:44:37.621098Z","shell.execute_reply":"2024-11-03T08:44:39.433471Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Below, I show my approach of using SAM with few-shot prompting to do accurate segmentation on rare classes","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/facebookresearch/segment-anything.git","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:54:48.655242Z","iopub.execute_input":"2024-10-29T13:54:48.656013Z","iopub.status.idle":"2024-10-29T13:55:07.112757Z","shell.execute_reply.started":"2024-10-29T13:54:48.655974Z","shell.execute_reply":"2024-10-29T13:55:07.111486Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install opencv-python pycocotools matplotlib onnxruntime onnx","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:55:11.169741Z","iopub.execute_input":"2024-10-29T13:55:11.170135Z","iopub.status.idle":"2024-10-29T13:55:25.226977Z","shell.execute_reply.started":"2024-10-29T13:55:11.170097Z","shell.execute_reply":"2024-10-29T13:55:25.225838Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from segment_anything import sam_model_registry, SamPredictor\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nsam_checkpoint = \"/kaggle/input/sam-vit/sam_vit_l_0b3195.pth\"\nmodel_type = \"vit_l\"\n\ndevice = \"cpu\"\n\nsam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\nsam.to(device=device)\n\npredictor = SamPredictor(sam)\nimage = np.array(Image.open(r\"/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset/test/frame12146_leftImg8bit.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-12T14:48:09.410551Z","iopub.execute_input":"2024-10-12T14:48:09.411191Z","iopub.status.idle":"2024-10-12T14:48:12.311817Z","shell.execute_reply.started":"2024-10-12T14:48:09.411153Z","shell.execute_reply":"2024-10-12T14:48:12.310788Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictor.set_image(image)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T14:48:12.31365Z","iopub.execute_input":"2024-10-12T14:48:12.313969Z","iopub.status.idle":"2024-10-12T14:48:35.727448Z","shell.execute_reply.started":"2024-10-12T14:48:12.313937Z","shell.execute_reply":"2024-10-12T14:48:35.726421Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimage = np.array(Image.open(r\"/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset/test/frame12146_leftImg8bit.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-29T16:12:27.525278Z","iopub.execute_input":"2024-10-29T16:12:27.52596Z","iopub.status.idle":"2024-10-29T16:12:27.610614Z","shell.execute_reply.started":"2024-10-29T16:12:27.525903Z","shell.execute_reply":"2024-10-29T16:12:27.609713Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_mask(mask, ax, random_color=False):\n    if random_color:\n        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n    else:\n        color = np.array([30/255, 144/255, 255/255, 0.6])\n    h, w = mask.shape[-2:]\n    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n    ax.imshow(mask_image)\n    \ndef show_points(coords, labels, ax, marker_size=375):\n    pos_points = coords[labels==1]\n    neg_points = coords[labels==0]\n    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n    \ndef show_box(box, ax):\n    x0, y0 = box[0], box[1]\n    w, h = box[2] - box[0], box[3] - box[1]\n    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:56:34.211574Z","iopub.execute_input":"2024-10-29T13:56:34.211968Z","iopub.status.idle":"2024-10-29T13:56:34.222506Z","shell.execute_reply.started":"2024-10-29T13:56:34.21193Z","shell.execute_reply":"2024-10-29T13:56:34.221621Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"** Here, I do few-shot prompting on the image that contains tunnel by selecting coordinates on the edges of the tunnel**","metadata":{}},{"cell_type":"code","source":"input_point = np.array([[250, 400], [1000, 100], [1750, 400]])\ninput_label = np.array([1, 1, 1])","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:56:35.02385Z","iopub.execute_input":"2024-10-29T13:56:35.02464Z","iopub.status.idle":"2024-10-29T13:56:35.029295Z","shell.execute_reply.started":"2024-10-29T13:56:35.02459Z","shell.execute_reply":"2024-10-29T13:56:35.028411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.imshow(image)\nshow_points(input_point, input_label, plt.gca())\nplt.axis('on')\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:56:35.429702Z","iopub.execute_input":"2024-10-29T13:56:35.430267Z","iopub.status.idle":"2024-10-29T13:56:36.170847Z","shell.execute_reply.started":"2024-10-29T13:56:35.430228Z","shell.execute_reply":"2024-10-29T13:56:36.169847Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"masks, scores, logits = predictor.predict(\n    point_coords=input_point,\n    point_labels=input_label,\n    multimask_output=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:56:45.216526Z","iopub.execute_input":"2024-10-29T13:56:45.217418Z","iopub.status.idle":"2024-10-29T13:56:45.249078Z","shell.execute_reply.started":"2024-10-29T13:56:45.217377Z","shell.execute_reply":"2024-10-29T13:56:45.248047Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_idx = np.argmax(scores)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:56:48.369914Z","iopub.execute_input":"2024-10-29T13:56:48.370698Z","iopub.status.idle":"2024-10-29T13:56:48.397906Z","shell.execute_reply.started":"2024-10-29T13:56:48.370657Z","shell.execute_reply":"2024-10-29T13:56:48.396704Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Here, we see that by few-shot prompting, we can greatly improve the accuracy on the rare classes, due to time constraints and lack of proper datasets on internet, I wasn't able to integrate this in my main pipeline, which I will try to do in the future**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.imshow(image)\nshow_mask(masks[max_idx], plt.gca())\nshow_points(input_point, input_label, plt.gca())\nplt.axis('off')\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:56:52.939531Z","iopub.execute_input":"2024-10-29T13:56:52.939929Z","iopub.status.idle":"2024-10-29T13:56:53.727904Z","shell.execute_reply.started":"2024-10-29T13:56:52.939892Z","shell.execute_reply":"2024-10-29T13:56:53.726679Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Selecting Key Images for Fine-Tuning on the basis of their Subdirectories:\n\nThe selection process begins by analyzing each directory to extract key features like the total number of unique images, the occurrence of rare classes, and the overall image count. For each directory:\n\n**Unique Image Count:** We first compute the total number of distinct images, ensuring no duplicates are considered.\n**Rare Class Representation:** We identify the rare classes present in the images. A rare class is defined based on its infrequent occurrence across the dataset. For each image, we parse the corresponding JSON files to extract class labels and flag those that belong to the underrepresented categories.\n**Total Image Count:** We then calculate the total number of images in each directory.\nNext, we assign weights to each of these metrics to capture their importance in the final selection:\n\n***α (Weight for unique images):*** This factor gives importance to directories containing a higher diversity of images.\n***β (Weight for rare class representation):*** This factor emphasizes directories that contribute rare class instances.\n***γ (Weight for image count):*** This accounts for the overall size of the directory in terms of the number of images.\nAfter normalizing these weighted values (so each metric contributes comparably), a composite score is calculated for each directory. The formula used to compute the final score for each directory \n𝐷 is:\n\nScore\n𝐷 = \n𝛼\n⋅\nnorm\n(\nunique images\n)\n+\n𝛽\n⋅\nnorm\n(\nrare classes\n)\n+\n𝛾\n⋅\nnorm\n(\ntotal images\n)\nFinally, directories are ranked based on their scores, and the top \nN directories with the highest scores are selected for fine-tuning the model. This ensures the sampled subset has a richer class representation and a balanced distribution of rare and frequent classes. ","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\n# Define rare classes\nrare_classes = ['tunnel','trailer', 'train', 'rectification border', 'rail track', 'parking']\n\n# Store the scores for each subdirectory\nsubdir_scores = {}\nbase_path = '/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset/labels'\n# Iterate over all subdirectories (e.g., 201, 202...)\nfor subdir in os.listdir(base_path):\n    class_count = {}\n    rare_class_count = 0\n    image_count = 0\n\n    # Get all JSON files (assuming the format is like frame{id}_polygons.json)\n    json_files = [f for f in os.listdir(os.path.join(base_path, subdir)) if f.endswith('_polygons.json')]\n\n    for json_file in json_files:\n        image_count += 1  # Increment image count\n        with open(os.path.join(os.path.join(base_path, subdir), json_file), 'r') as file:\n            data = json.load(file)\n            for obj in data['objects']:\n                label = obj['label']\n                # Count class occurrences\n                if label in class_count:\n                    class_count[label] += 1\n                else:\n                    class_count[label] = 1\n\n                # Count rare class occurrences\n                if label in rare_classes:\n                    rare_class_count += 1\n\n    # Calculate the class diversity score\n    class_diversity_score = len(class_count)  # Number of unique classes\n\n    # Store the subdirectory scores\n    subdir_scores[subdir] = {\n        'class_diversity_score': class_diversity_score,\n        'rare_class_score': rare_class_count,\n        'image_count': image_count\n    }\n\n# Normalize the scores and calculate the weighted score\nmax_class_diversity = max([v['class_diversity_score'] for v in subdir_scores.values()])\nmax_rare_class = max([v['rare_class_score'] for v in subdir_scores.values()])\nmax_image_count = max([v['image_count'] for v in subdir_scores.values()])\n\nα, β, γ = 0.4, 0.45, 0.15  # Example weights\n\nfor subdir, scores in subdir_scores.items():\n    weighted_score = (\n        α * (scores['class_diversity_score'] / max_class_diversity) +\n        β * (scores['rare_class_score'] / max_rare_class) +\n        γ * (scores['image_count'] / max_image_count)\n    )\n    subdir_scores[subdir]['weighted_score'] = weighted_score\n\n# Sort the subdirectories based on weighted score\nranked_subdirs = sorted(subdir_scores.items(), key=lambda x: x[1]['weighted_score'], reverse=True)\n\n# Select top N subdirectories for dataset creation\n# top_subdirs = [subdir for subdir, scores in ranked_subdirs[:N]]  # N is the number of subdirs to sample","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:45:27.408906Z","iopub.execute_input":"2024-11-03T08:45:27.409417Z","iopub.status.idle":"2024-11-03T08:46:22.963129Z","shell.execute_reply.started":"2024-11-03T08:45:27.40936Z","shell.execute_reply":"2024-11-03T08:46:22.96231Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"needed_count = 0\nfor i, (k, v) in enumerate(ranked_subdirs):\n    print(k, v['weighted_score'], v['image_count'])\n    needed_count += v['image_count']\n    print(i+1, \" \", needed_count)","metadata":{"id":"1_38lyAyOfJa","execution":{"iopub.status.busy":"2024-11-03T08:46:22.964634Z","iopub.execute_input":"2024-11-03T08:46:22.964958Z","iopub.status.idle":"2024-11-03T08:46:22.984066Z","shell.execute_reply.started":"2024-11-03T08:46:22.964924Z","shell.execute_reply":"2024-11-03T08:46:22.983217Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N = 9\ntop_subdirs = [subdir for subdir, scores in ranked_subdirs[:N]]\ntop_subdirs","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:46:22.985322Z","iopub.execute_input":"2024-11-03T08:46:22.985611Z","iopub.status.idle":"2024-11-03T08:46:22.99848Z","shell.execute_reply.started":"2024-11-03T08:46:22.985581Z","shell.execute_reply":"2024-11-03T08:46:22.997708Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"color_to_id = {tuple(label.color) : label.id for label in labels_details}\ndef convert(seg_map):\n    # Convert the segmentation map image to a numpy array of shape (H, W, 3) where each pixel has RGB values\n    seg_map_array = np.array(seg_map.convert('RGB').resize((512,512)))\n\n    # Create an empty H * W array to store the pixel-wise label values (id values)\n    id_array = np.zeros((seg_map_array.shape[0], seg_map_array.shape[1]), dtype=np.int32)\n\n    # Iterate over each pixel in the segmentation map\n    for i in range(seg_map_array.shape[0]):\n        for j in range(seg_map_array.shape[1]):\n            pixel_color = tuple(seg_map_array[i, j])\n            # Lookup the corresponding id for the pixel's color\n            id_array[i, j] = color_to_id.get(pixel_color, -1)  # Default to -1 if the color is not found\n\n    return id_array\n\ndef get_identifier(filename):\n    parts = filename.split('_')\n    if 'frame' in parts[0]:\n        return parts[0].replace('frame', '')  # Get ID after 'frame'\n    else:\n        return parts[0]  # Get numeric part in filename","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:46:23.000409Z","iopub.execute_input":"2024-11-03T08:46:23.000801Z","iopub.status.idle":"2024-11-03T08:46:23.009224Z","shell.execute_reply.started":"2024-11-03T08:46:23.000754Z","shell.execute_reply":"2024-11-03T08:46:23.008343Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import PIL.Image as Image\nimg = Image.open('/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset/labels/201/frame0029_gtFine_labelColors.png')\nimg = convert(img)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:46:23.01039Z","iopub.execute_input":"2024-11-03T08:46:23.010735Z","iopub.status.idle":"2024-11-03T08:46:25.35411Z","shell.execute_reply.started":"2024-11-03T08:46:23.010703Z","shell.execute_reply":"2024-11-03T08:46:25.35309Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(np.array(img))","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:46:25.355344Z","iopub.execute_input":"2024-11-03T08:46:25.355737Z","iopub.status.idle":"2024-11-03T08:46:25.671355Z","shell.execute_reply.started":"2024-11-03T08:46:25.355697Z","shell.execute_reply":"2024-11-03T08:46:25.670465Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Extracting the dataset from the given dataset for finetuning based on the top subdirs that we got from the ranking based on the custom criteria","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\nfrom multiprocessing import Process, Queue\n# Base directory path\nbase_dir = '/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset'\ntrain_dir = os.path.join(base_dir, 'train')\nlabels_dir = os.path.join(base_dir, 'labels')\n# Array to store the dataset\ndata_set = []\n\ntop_subdirs.insert(0, \"296\")\n# Get the list of subdirectories\nsubdirs = [dirname for dirname in top_subdirs]\n\n# Process images sequentially\nfor dirname in tqdm(subdirs, desc=\"Processing directories\"):\n    train_subdir = os.path.join(train_dir, dirname)\n    labels_subdir = os.path.join(labels_dir, dirname)\n\n    if os.path.isdir(train_subdir) and os.path.isdir(labels_subdir):\n        # Get the list of train images and label images\n        train_images = [f for f in os.listdir(train_subdir) if f.endswith('.jpg')]\n        label_images = [f for f in os.listdir(labels_subdir) if f.endswith('labelColors.png')]\n\n        # Match train and label images based on the {ID}\n        for label_image in label_images:\n            identifier = get_identifier(label_image)  # Extract {ID} from label filename\n\n            # Find the matching train image\n            matched_train_image = next((img for img in train_images if identifier in img), None)\n\n            if matched_train_image:\n                # Process the image pair sequentially\n                pixel_image_path = os.path.join(train_subdir, matched_train_image)\n                label_image_path = os.path.join(labels_subdir, label_image)\n\n                pixel_image = Image.open(pixel_image_path).resize((512,512))  # Train image\n                label_image_tensor = convert(Image.open(label_image_path))   # Label image transformed to label IDs\n\n                data_set.append({\n                    'pixel_values': pixel_image,  # Train image as PIL Image\n                    'label': label_image_tensor  # Label image as torch tensor on GPU (if available)\n                })\n\n# Example to show the contents of data_set\nfor idx, data in enumerate(data_set[:3]):  # Show first 3 entries\n    print(f\"Index {idx}:\")\n    print(f\"Pixels Image: {data['pixel_values']}\")\n    # print(f\"Labels Image (Tensor on {device}): {data['label']}\")  # Labels are stored as tensors on GPU if available\n\n\nimport pickle\n# Save the data_set using pickle\nsave_path = '/kaggle/working/data_s.pkl'\n\nwith open(save_path, 'wb') as file:\n    pickle.dump(data_set, file)\n\nprint(f'data_set saved to {save_path}')","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:52:26.16827Z","iopub.execute_input":"2024-11-03T08:52:26.168668Z","iopub.status.idle":"2024-11-03T08:55:53.835881Z","shell.execute_reply.started":"2024-11-03T08:52:26.168629Z","shell.execute_reply":"2024-11-03T08:55:53.834411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nimport os\nimport torch\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\nfrom multiprocessing import Process, Queue\n# Loading the dataset for finetuning saved in .pkl format\npkl_file_path = '/kaggle/input/finetune/data_s.pkl'\n\n# Open and load the .pkl file\nwith open(pkl_file_path, 'rb') as f:\n    data_set = pickle.load(f)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:56:05.090412Z","iopub.execute_input":"2024-11-03T08:56:05.091114Z","iopub.status.idle":"2024-11-03T08:56:17.425236Z","shell.execute_reply.started":"2024-11-03T08:56:05.091073Z","shell.execute_reply":"2024-11-03T08:56:17.424381Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Now, using HF libraries to convert our dataset in the proper format and also loading the pretrained Mask2Former model**","metadata":{}},{"cell_type":"code","source":"!pip install evaluate","metadata":{"id":"6T3Qm3WwRGmJ","outputId":"48b4149a-0045-4a0c-baf6-a9a9fec54618","execution":{"iopub.status.busy":"2024-11-03T08:56:17.428361Z","iopub.execute_input":"2024-11-03T08:56:17.428685Z","iopub.status.idle":"2024-11-03T08:56:30.518685Z","shell.execute_reply.started":"2024-11-03T08:56:17.428651Z","shell.execute_reply":"2024-11-03T08:56:30.517558Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install datasets","metadata":{"id":"XrLXao0F_WG2","outputId":"b94b50b3-6bae-44e2-87b5-e159ff2e05f8","execution":{"iopub.status.busy":"2024-11-03T08:56:30.520269Z","iopub.execute_input":"2024-11-03T08:56:30.520699Z","iopub.status.idle":"2024-11-03T08:56:42.242335Z","shell.execute_reply.started":"2024-11-03T08:56:30.52066Z","shell.execute_reply":"2024-11-03T08:56:42.241352Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nimport datasets\nimport requests\nimport evaluate\nimport numpy as np\nimport huggingface_hub\nfrom PIL import Image\nimport albumentations as A\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nfrom typing import Tuple, Any\nfrom dataclasses import dataclass\nfrom datasets import load_dataset\nimport matplotlib.patches as mpatches\nfrom huggingface_hub import hf_hub_download\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    Mask2FormerImageProcessor,\n    AutoImageProcessor,\n    Mask2FormerForUniversalSegmentation,\n)\n\ntorch.manual_seed(42)","metadata":{"id":"x_8ZhjffOwgY","outputId":"2e4944c5-8518-4a83-876f-f8dba9ecb1ab","execution":{"iopub.status.busy":"2024-11-03T08:56:42.244478Z","iopub.execute_input":"2024-11-03T08:56:42.244835Z","iopub.status.idle":"2024-11-03T08:56:57.931137Z","shell.execute_reply.started":"2024-11-03T08:56:42.244784Z","shell.execute_reply":"2024-11-03T08:56:57.93006Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# it seems that we need to login to huggingface to have access to the dataset segments/sidewalk-semantic\nhuggingface_hub.notebook_login()","metadata":{"id":"_IZxlP0rxM4f","outputId":"736367aa-d04e-446b-eb45-a91a4acfd215","execution":{"iopub.status.busy":"2024-10-29T14:14:42.037306Z","iopub.execute_input":"2024-10-29T14:14:42.038192Z","iopub.status.idle":"2024-10-29T14:14:42.066472Z","shell.execute_reply.started":"2024-10-29T14:14:42.038149Z","shell.execute_reply":"2024-10-29T14:14:42.065593Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_dict({\"pixel_values\": [item[\"pixel_values\"] for item in data_set],\n                             \"label\": [item[\"label\"] for item in data_set]})","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:57:01.897462Z","iopub.execute_input":"2024-11-03T08:57:01.898489Z","iopub.status.idle":"2024-11-03T08:59:48.253108Z","shell.execute_reply.started":"2024-11-03T08:57:01.898445Z","shell.execute_reply":"2024-11-03T08:59:48.252021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = dataset.shuffle(seed=1)\ndataset = dataset.train_test_split(test_size=0.1)\ntrain_ds, test_ds = dataset[\"train\"], dataset[\"test\"]\n\ndataset = train_ds.train_test_split(test_size=0.05)\ntrain_ds, val_ds = dataset[\"train\"], dataset[\"test\"]","metadata":{"id":"u2GYIblNQKvs","outputId":"2596d448-be1c-416d-ed8e-878cab9a89a8","execution":{"iopub.status.busy":"2024-11-03T08:59:48.255093Z","iopub.execute_input":"2024-11-03T08:59:48.255417Z","iopub.status.idle":"2024-11-03T08:59:48.286393Z","shell.execute_reply.started":"2024-11-03T08:59:48.255384Z","shell.execute_reply":"2024-11-03T08:59:48.285626Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds","metadata":{"id":"G_mcEd1-RjA9","outputId":"db4888e9-d0f8-4072-a0b0-4b63e6073999","execution":{"iopub.status.busy":"2024-11-03T08:59:48.287375Z","iopub.execute_input":"2024-11-03T08:59:48.287649Z","iopub.status.idle":"2024-11-03T08:59:48.293471Z","shell.execute_reply.started":"2024-11-03T08:59:48.287619Z","shell.execute_reply":"2024-11-03T08:59:48.292608Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id2label = id_to_label_map()\nprint(id2label)","metadata":{"id":"20yOq90_QmF9","outputId":"0e414ac6-b97c-47ba-8daa-1f71ab225843","execution":{"iopub.status.busy":"2024-11-03T08:59:48.295819Z","iopub.execute_input":"2024-11-03T08:59:48.296179Z","iopub.status.idle":"2024-11-03T08:59:48.303634Z","shell.execute_reply.started":"2024-11-03T08:59:48.296137Z","shell.execute_reply":"2024-11-03T08:59:48.302811Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now,the dataset contains two fields:`pixel_values` and `label`.\n\n- `pixel_values` is an RGB image of shape (H, W, 3)\n- `label` is a segmentation map of shape (H, W) that contains the label of each pixel in the image.\n","metadata":{"id":"8bn3zKE64Plv"}},{"cell_type":"code","source":"example = train_ds[0]\nprint(example)\nsegmentation_map = np.array(example[\"label\"])\nimage_array = np.array(example[\"pixel_values\"])\nprint(\n    f\"Shape : Image: {image_array.shape} - Segmentation map: {segmentation_map.shape}\"\n)\n\nprint(segmentation_map)","metadata":{"id":"FtbOb-tr5Nrn","outputId":"60d5306e-cbfb-4b68-e427-5ac8ca0675f6","execution":{"iopub.status.busy":"2024-11-03T08:59:48.304645Z","iopub.execute_input":"2024-11-03T08:59:48.304932Z","iopub.status.idle":"2024-11-03T08:59:48.538296Z","shell.execute_reply.started":"2024-11-03T08:59:48.304901Z","shell.execute_reply":"2024-11-03T08:59:48.537435Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Now, we visualise some samples from the dataset to check if they are stored correctly_\n","metadata":{"id":"kPpPl-BB9Ia9"}},{"cell_type":"code","source":"def show_samples(dataset: datasets.Dataset, n: int = 5):\n    \"\"\"\n    Displays 'n' samples from the dataset.\n    ----\n    Args:\n      - dataset: The dataset which should contain 'pixel_values' and 'label' in its items.\n      - n (int): Number of samples to display.\n\n    \"\"\"\n    if n > len(dataset):\n        raise ValueError(\"n is larger than the dataset size\")\n\n    fig, axs = plt.subplots(n, 2, figsize=(10, 5 * n))\n\n    for i in range(n):\n        sample = dataset[i]\n        image, label = np.array(sample[\"pixel_values\"]), sample[\"label\"]\n\n        axs[i, 0].imshow(image)\n        axs[i, 0].set_title(\"Image\")\n        axs[i, 0].axis(\"off\")\n\n        axs[i, 1].imshow(image)\n        axs[i, 1].imshow(label, cmap=\"nipy_spectral\", alpha=1.0)\n        axs[i, 1].set_title(\"Segmentation Map\")\n        axs[i, 1].axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"qHqdou_i15UE","execution":{"iopub.status.busy":"2024-11-03T08:59:48.539533Z","iopub.execute_input":"2024-11-03T08:59:48.539896Z","iopub.status.idle":"2024-11-03T08:59:48.551689Z","shell.execute_reply.started":"2024-11-03T08:59:48.539858Z","shell.execute_reply":"2024-11-03T08:59:48.550839Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_samples(train_ds, n=4)","metadata":{"id":"LXL7X3dD0YRh","outputId":"681f66f5-ed50-419f-d728-d31869758374","execution":{"iopub.status.busy":"2024-11-03T08:59:48.5531Z","iopub.execute_input":"2024-11-03T08:59:48.553528Z","iopub.status.idle":"2024-11-03T08:59:50.99663Z","shell.execute_reply.started":"2024-11-03T08:59:48.553489Z","shell.execute_reply":"2024-11-03T08:59:50.995217Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preparing the Dataset for training\n\nHere, we use the Mask2Former Image Preprocessor to transform the images in the corresponding format expected by the model\n\nTo improve the robustness of the model under different rotations, scaling, or lighting conditions, we apply data augmentations (namely **random croping**, **flipping** and **normalizing**) to the training dataset\n\nWe also do normalisation of the images using the mean and std_deviation which improves the performance and the convergence of the model.\n","metadata":{"id":"_8jPobCe4H3L"}},{"cell_type":"markdown","source":"Below, we create a custom Semantic Segmentation Dataset and define a dataloader with a custom collator function that does the mask2former image preprocessing on the images","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom dataclasses import dataclass\nimport numpy as np\nfrom typing import Any, Tuple, List, Union\n\nfrom transformers import Mask2FormerImageProcessor\n\npreprocessor = Mask2FormerImageProcessor(\n    ignore_index=0,\n    do_reduce_labels=False,\n    do_resize=False,\n    do_rescale=False,\n    do_normalize=False,\n)\n\nade_mean = [123.675 / 255, 116.280 / 255, 103.530 / 255]\nade_std = [58.395 / 255, 57.120 / 255, 57.375 / 255]\n\nclass SegmentationTransform:\n    def __init__(self, is_train=True):\n        self.is_train = is_train\n        self.img_transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=ade_mean, std=ade_std)\n        ])\n        if self.is_train:\n            self.img_transform = transforms.Compose([\n                transforms.RandomHorizontalFlip(p=0.5),\n                self.img_transform\n            ])\n\n    def __call__(self, image, mask):\n        image = self.img_transform(image)\n        mask = torch.from_numpy(np.array(mask)).long()\n        if self.is_train and torch.rand(1) < 0.5:\n            image = torch.flip(image, dims=[2])\n            mask = torch.flip(mask, dims=[1])\n        return image, mask\n\n@dataclass\nclass SegmentationDataInput:\n    original_image: np.ndarray\n    transformed_image: torch.Tensor\n    original_segmentation_map: np.ndarray\n    transformed_segmentation_map: torch.Tensor\n\nclass SemanticSegmentationDataset(Dataset):\n    def __init__(self, dataset: Any, is_train: bool = True) -> None:\n        \"\"\"\n        Dataset for Semantic Segmentation.\n        ----\n        Args:\n          - dataset: A dataset containing images and segmentation maps.\n          - is_train: Whether this is a training dataset (for augmentations).\n        \"\"\"\n        self.dataset = dataset\n        self.transform = SegmentationTransform(is_train)\n\n    def __len__(self) -> int:\n        return len(self.dataset)\n\n    def __getitem__(self, idx: int) -> SegmentationDataInput:\n        sample = self.dataset[idx]\n        original_image = sample[\"pixel_values\"]\n        original_segmentation_map = sample['label']\n        \n        transformed_image, transformed_segmentation_map = self.transform(original_image, original_segmentation_map)\n        original_segmentation_map = np.array(original_segmentation_map)\n        original_segmentation_map[original_segmentation_map == -1] = 35\n        transformed_segmentation_map[transformed_segmentation_map == -1] = 35\n        return SegmentationDataInput(\n            original_image=np.array(original_image),\n            transformed_image=transformed_image,\n            original_segmentation_map=original_segmentation_map,\n            transformed_segmentation_map=transformed_segmentation_map,\n        )\n\ndef collate_fn(batch: List[SegmentationDataInput]) -> dict:\n    original_images = [sample.original_image for sample in batch]\n    transformed_images = [sample.transformed_image for sample in batch]\n    original_segmentation_maps = [sample.original_segmentation_map for sample in batch]\n    transformed_segmentation_maps = [sample.transformed_segmentation_map for sample in batch]\n\n    preprocessed_batch = preprocessor(\n        transformed_images,\n        segmentation_maps=transformed_segmentation_maps,\n        return_tensors=\"pt\",\n    )\n    preprocessed_batch[\"original_images\"] = original_images\n    preprocessed_batch[\"original_segmentation_maps\"] = original_segmentation_maps\n    return preprocessed_batch\n\n# Prepare Datasets\ntrain_dataset = SemanticSegmentationDataset(train_ds, is_train=True)\nval_dataset = SemanticSegmentationDataset(val_ds, is_train=False)\ntest_dataset = SemanticSegmentationDataset(test_ds, is_train=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:02:59.188635Z","iopub.execute_input":"2024-11-03T09:02:59.18966Z","iopub.status.idle":"2024-11-03T09:02:59.208813Z","shell.execute_reply.started":"2024-11-03T09:02:59.189616Z","shell.execute_reply":"2024-11-03T09:02:59.20784Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare Dataloaders\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn\n)\nval_dataloader = DataLoader(\n    val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:03:19.10726Z","iopub.execute_input":"2024-11-03T09:03:19.107656Z","iopub.status.idle":"2024-11-03T09:03:19.113524Z","shell.execute_reply.started":"2024-11-03T09:03:19.10762Z","shell.execute_reply":"2024-11-03T09:03:19.112601Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in train_dataloader:\n    print(i.keys())\n    break","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:03:20.634254Z","iopub.execute_input":"2024-11-03T09:03:20.634858Z","iopub.status.idle":"2024-11-03T09:03:22.804784Z","shell.execute_reply.started":"2024-11-03T09:03:20.634779Z","shell.execute_reply":"2024-11-03T09:03:22.803537Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = next(iter(train_dataloader))\nprint(\n    {\n        key: value[0].shape if isinstance(value, list) else value.shape\n        for key, value in sample.items()\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:03:25.108859Z","iopub.execute_input":"2024-11-03T09:03:25.109808Z","iopub.status.idle":"2024-11-03T09:03:26.971772Z","shell.execute_reply.started":"2024-11-03T09:03:25.10975Z","shell.execute_reply":"2024-11-03T09:03:26.970834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nHere, we check that the dataset is loaded in the correct format and all the key things for each image are loaded and follow the proper dimensions and values\n","metadata":{"id":"6uFWfji4QOsJ"}},{"cell_type":"code","source":"sample = next(iter(train_dataloader))\n# sample['class_labels'] = [torch.where(label == -1, torch.tensor(35), label) for label in sample['class_labels']]\nprint(\n    {\n        key: value[0].shape if isinstance(value, list) else value.shape\n        for key, value in sample.items()\n    }\n)","metadata":{"id":"AERhcfIc4Gv5","outputId":"dfa1fe00-2853-43b7-e277-fb091d6a7013","execution":{"iopub.status.busy":"2024-10-31T03:31:51.126329Z","iopub.execute_input":"2024-10-31T03:31:51.126738Z","iopub.status.idle":"2024-10-31T03:31:53.050686Z","shell.execute_reply.started":"2024-10-31T03:31:51.126702Z","shell.execute_reply":"2024-10-31T03:31:53.049649Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Let's verify now that the normalization is done correctly by doing the opposite operation (denormalization)_\n","metadata":{"id":"FJeBtCQMUDpo"}},{"cell_type":"code","source":"def denormalize_image(image, mean, std):\n    \"\"\"\n    Denormalizes a normalized image.\n    ----\n    Args:\n     - image (numpy.ndarray): The normalized image.\n     - mean (list or numpy.ndarray): The mean used for normalization.\n     - std (list or numpy.ndarray): The standard deviation used for normalization.\n\n    \"\"\"\n    unnormalized_image = (image * std[:, None, None]) + mean[:, None, None]\n    unnormalized_image = (unnormalized_image * 255).numpy().astype(np.uint8)\n    unnormalized_image = np.moveaxis(unnormalized_image, 0, -1)\n    return unnormalized_image\n\nade_mean = np.array(ade_mean)\nade_std = np.array(ade_std)\ndenormalized_image = denormalize_image(sample[\"pixel_values\"][0], ade_mean, ade_std)\npil_image = Image.fromarray(denormalized_image)\npil_image","metadata":{"id":"45ijY5rV4GVA","outputId":"494f05b1-564e-45df-f3b0-78bbaeb25271","execution":{"iopub.status.busy":"2024-11-03T09:03:32.56333Z","iopub.execute_input":"2024-11-03T09:03:32.563769Z","iopub.status.idle":"2024-11-03T09:03:32.64151Z","shell.execute_reply.started":"2024-11-03T09:03:32.563725Z","shell.execute_reply":"2024-11-03T09:03:32.640541Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Finally, we will verify the consistency between `mask_labels` and `class_labels` :_\n","metadata":{"id":"8CcWbxRfUcm2"}},{"cell_type":"code","source":"labels = [id2label[label] for label in sample[\"class_labels\"][0].tolist()]\nprint(labels)","metadata":{"id":"FvT4uxZn4FyK","outputId":"442a6f79-9cba-4d45-fcf5-76d267f9e97f","execution":{"iopub.status.busy":"2024-11-03T09:03:35.87246Z","iopub.execute_input":"2024-11-03T09:03:35.873342Z","iopub.status.idle":"2024-11-03T09:03:35.878281Z","shell.execute_reply.started":"2024-11-03T09:03:35.873301Z","shell.execute_reply":"2024-11-03T09:03:35.877379Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_mask(sample, labels, label_name):\n    print(f\"Category: {label_name}\")\n    idx = labels.index(label_name)\n\n    visual_mask = (sample[\"mask_labels\"][0][idx].bool().numpy() * 255).astype(np.uint8)\n    return Image.fromarray(visual_mask)","metadata":{"id":"AA7Av8ErPuAM","execution":{"iopub.status.busy":"2024-11-03T09:03:36.327427Z","iopub.execute_input":"2024-11-03T09:03:36.327836Z","iopub.status.idle":"2024-11-03T09:03:36.333388Z","shell.execute_reply.started":"2024-11-03T09:03:36.327797Z","shell.execute_reply":"2024-11-03T09:03:36.33242Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample['mask_labels'][0].shape","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:03:38.229772Z","iopub.execute_input":"2024-11-03T09:03:38.230203Z","iopub.status.idle":"2024-11-03T09:03:38.236724Z","shell.execute_reply.started":"2024-11-03T09:03:38.230165Z","shell.execute_reply":"2024-11-03T09:03:38.235752Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_mask(sample, labels, labels[0])","metadata":{"id":"vaPDV0KWPt14","outputId":"29972e5f-ac0a-4a97-e0fe-9dad4987b118","execution":{"iopub.status.busy":"2024-11-03T09:03:38.575883Z","iopub.execute_input":"2024-11-03T09:03:38.576273Z","iopub.status.idle":"2024-11-03T09:03:38.587163Z","shell.execute_reply.started":"2024-11-03T09:03:38.576236Z","shell.execute_reply":"2024-11-03T09:03:38.586058Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading model for semantic segmentation\n","metadata":{"id":"goNWFexZUuAt"}},{"cell_type":"markdown","source":"### Model Choice\n\n[Mask2Former (Cheng et al., 2022)](https://arxiv.org/pdf/2112.01527) is a versatile model designed to unify the tasks of semantic, instance, and panoptic segmentation, similar to MaskFormer, but with key enhancements that improve performance across these tasks. Mask2Former builds on the success of MaskFormer by refining the way mask predictions are made through iterative processing, leading to better segmentation quality.\n\nMask2Former improves segmentation by incorporating a *transformer-based pixel decoder* and leveraging *multi-scale features*, allowing the model to predict masks more accurately across different image resolutions.\n\nThe architecture of Mask2Former consists of the following components:\n\n- **Backbone**: A pre-trained Convolutional Neural Network (CNN) or Vision Transformer (ViT) that processes the input image into a set of feature maps at multiple scales, producing rich representations for the next steps.\n  \n- **Pixel Decoder**: This component is enhanced compared to MaskFormer. It processes multi-scale features from the backbone and generates per-pixel embeddings for each scale, which are then combined to provide multi-level feature representations. This multi-scale pixel decoder improves the model’s ability to capture fine details and larger contextual information.\n\n- **Transformer Decoder with Cross-Attention**: Mask2Former introduces a more sophisticated transformer decoder that performs *iterative cross-attention*. It refines a fixed set of learnable queries by iterating between image features and segment embeddings. This iterative process helps in producing more precise segment representations by refining object features step by step.\n\n- **Multi-Scale Mask Prediction**: Mask2Former predicts segmentation masks at multiple scales, with the model learning to output fine and coarse mask predictions for each segment. This enables it to handle objects of different sizes and improves segmentation accuracy, especially for small or overlapping objects.\n\n- **Class and Mask Prediction**: Similar to MaskFormer, the final outputs include class predictions for each segment and the corresponding binary masks. The model assigns a class label to each predicted segment, along with a unique mask for instance segmentation. Panoptic segmentation is achieved by combining the class and instance predictions, assigning both a category and a unique ID to every pixel in the image.\n\nThe iterative mask prediction mechanism, combined with multi-scale feature processing, makes Mask2Former more effective than MaskFormer in handling challenging scenarios like occlusions, small object detection, and fine-grained segmentation, offering state-of-the-art performance across semantic, instance, and panoptic segmentation tasks.\n\n<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/mask2former_architecture.jpg\" alt=\"Mask2Former Architecture\" width=\"400\" height=\"100\"/>\n","metadata":{}},{"cell_type":"markdown","source":"### Semantic Segmentation\n\nSemantic segmentation is the task of classifying each pixel in an image into a category effectively grouping parts of the image into distinct objects.\n","metadata":{"id":"pWu7p-36vJHl"}},{"cell_type":"code","source":"processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-ade-semantic\")\nmodel = Mask2FormerForUniversalSegmentation.from_pretrained(\n    \"facebook/mask2former-swin-large-ade-semantic\"\n)","metadata":{"id":"lcXg7gR-sRo6","outputId":"7d1c395d-7b51-46ec-e5dc-aebad77645d1","execution":{"iopub.status.busy":"2024-11-03T09:03:42.634855Z","iopub.execute_input":"2024-11-03T09:03:42.635246Z","iopub.status.idle":"2024-11-03T09:03:47.753209Z","shell.execute_reply.started":"2024-11-03T09:03:42.635208Z","shell.execute_reply":"2024-11-03T09:03:47.752388Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image = Image.fromarray(denormalized_image)\nimage","metadata":{"id":"rtE0V8i6yPHq","outputId":"6f3d19d5-5a90-4265-c7c0-bbe476c565c5","execution":{"iopub.status.busy":"2024-11-03T09:03:49.624927Z","iopub.execute_input":"2024-11-03T09:03:49.625325Z","iopub.status.idle":"2024-11-03T09:03:49.675649Z","shell.execute_reply.started":"2024-11-03T09:03:49.625283Z","shell.execute_reply":"2024-11-03T09:03:49.674828Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = processor(images=image, return_tensors=\"pt\")\nwith torch.no_grad():\n    outputs = model(**inputs)\n\npredicted_semantic_map = processor.post_process_semantic_segmentation(\n    outputs, target_sizes=[image.size[::-1]]\n)[0]\npredicted_semantic_map","metadata":{"id":"N8oH8vW3vDEm","outputId":"37b17427-8876-4585-9625-76fb60d5027e","execution":{"iopub.status.busy":"2024-11-03T09:03:49.868605Z","iopub.execute_input":"2024-11-03T09:03:49.868987Z","iopub.status.idle":"2024-11-03T09:03:54.097084Z","shell.execute_reply.started":"2024-11-03T09:03:49.86895Z","shell.execute_reply":"2024-11-03T09:03:54.09617Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.any(predicted_semantic_map == -1)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:03:56.761884Z","iopub.execute_input":"2024-11-03T09:03:56.762538Z","iopub.status.idle":"2024-11-03T09:03:56.769537Z","shell.execute_reply.started":"2024-11-03T09:03:56.762496Z","shell.execute_reply":"2024-11-03T09:03:56.768587Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(predicted_semantic_map)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:03:57.744668Z","iopub.execute_input":"2024-11-03T09:03:57.745399Z","iopub.status.idle":"2024-11-03T09:03:57.759983Z","shell.execute_reply.started":"2024-11-03T09:03:57.745358Z","shell.execute_reply":"2024-11-03T09:03:57.758932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(np.unique(predicted_semantic_map))\ncmap = plt.cm.get_cmap(\"hsv\", num_classes)\n\noverlay = np.zeros(\n    (predicted_semantic_map.shape[0], predicted_semantic_map.shape[1], 4)\n)\n\nfor i, unique_value in enumerate(np.unique(predicted_semantic_map)):\n    overlay[predicted_semantic_map == unique_value, :3] = cmap(i)[:3]\n    overlay[predicted_semantic_map == unique_value, 3] = 0.5  # 50% transparency\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.imshow(image)\nax.imshow(overlay, interpolation=\"nearest\", alpha=0.9)\nplt.axis(\"off\")\n\nplt.show()","metadata":{"id":"3rQKOykr0APc","outputId":"364aaa9d-68dd-4403-9cf7-626caccf26be","execution":{"iopub.status.busy":"2024-11-03T09:04:00.924764Z","iopub.execute_input":"2024-11-03T09:04:00.925644Z","iopub.status.idle":"2024-11-03T09:04:01.301343Z","shell.execute_reply.started":"2024-11-03T09:04:00.925602Z","shell.execute_reply":"2024-11-03T09:04:01.300473Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(id2label)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:04:03.376699Z","iopub.execute_input":"2024-11-03T09:04:03.377111Z","iopub.status.idle":"2024-11-03T09:04:03.383524Z","shell.execute_reply.started":"2024-11-03T09:04:03.377072Z","shell.execute_reply":"2024-11-03T09:04:03.382473Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = next(iter(train_dataloader))\nsample['class_labels']","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:04:04.58527Z","iopub.execute_input":"2024-11-03T09:04:04.58621Z","iopub.status.idle":"2024-11-03T09:04:06.435119Z","shell.execute_reply.started":"2024-11-03T09:04:04.586169Z","shell.execute_reply":"2024-11-03T09:04:06.434237Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = next(iter(train_dataloader))\n# sample['class_labels'] = [torch.where(label == -1, torch.tensor(35), label) for label in sample['class_labels']]\noutputs = model(\n    pixel_values=sample[\"pixel_values\"],\n    pixel_mask=sample[\"pixel_mask\"],\n    class_labels=sample[\"class_labels\"],\n    mask_labels=sample[\"mask_labels\"],\n)\nprint(outputs.loss)","metadata":{"id":"r9Sfnk7ChKh3","outputId":"70c8a2b3-7017-4aad-d1e1-a219d3a95627","execution":{"iopub.status.busy":"2024-10-31T03:33:18.878312Z","iopub.execute_input":"2024-10-31T03:33:18.878711Z","iopub.status.idle":"2024-10-31T03:33:43.729178Z","shell.execute_reply.started":"2024-10-31T03:33:18.878674Z","shell.execute_reply":"2024-10-31T03:33:43.727588Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Loading the Mask2Former model, now modifying the output layer with the id2label map such that the model gets finetuned for the classes in our dataset**","metadata":{}},{"cell_type":"code","source":"model = Mask2FormerForUniversalSegmentation.from_pretrained(\n    \"facebook/mask2former-swin-large-ade-semantic\", id2label=id2label, ignore_mismatched_sizes=True\n)","metadata":{"id":"-qsAoU7kHYPB","outputId":"531198df-e920-4b77-beaa-de171dd8bac3","execution":{"iopub.status.busy":"2024-11-03T09:04:12.919695Z","iopub.execute_input":"2024-11-03T09:04:12.920118Z","iopub.status.idle":"2024-11-03T09:04:17.783816Z","shell.execute_reply.started":"2024-11-03T09:04:12.920078Z","shell.execute_reply":"2024-11-03T09:04:17.782977Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample[0]['class_labels']","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:04:22.836658Z","iopub.execute_input":"2024-11-03T09:04:22.83758Z","iopub.status.idle":"2024-11-03T09:04:23.361977Z","shell.execute_reply.started":"2024-11-03T09:04:22.837538Z","shell.execute_reply":"2024-11-03T09:04:23.360707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training\n","metadata":{"id":"tbeiNy9bG17v"}},{"cell_type":"markdown","source":"Here, we divide our model into freezing parts, the ones that we wont finetune and the training parts that we will finetune:\n\n**Freezing Components**: The Backbone and the Pixel Decoder will be frozen. Their pre-trained weights capture universal features applicable across different datasets and domains.\n\n**Training Components**: The Transformer Decoder and MLP layer will be fine-tuned. This process customizes the segment embeddings and classification layers.\n","metadata":{"id":"ABV5klcWs7dt"}},{"cell_type":"code","source":"# pixel level module contains both the backbone and the pixel decoder\nfor param in model.model.pixel_level_module.parameters():\n    param.requires_grad = False\n\n# Confirm that the parameters are correctly frozen\nfor name, param in model.model.pixel_level_module.named_parameters():\n    assert not param.requires_grad","metadata":{"id":"xy3Jo6u5a8wz","execution":{"iopub.status.busy":"2024-11-03T09:04:29.470145Z","iopub.execute_input":"2024-11-03T09:04:29.470532Z","iopub.status.idle":"2024-11-03T09:04:29.481709Z","shell.execute_reply.started":"2024-11-03T09:04:29.470494Z","shell.execute_reply":"2024-11-03T09:04:29.480822Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id2label","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:04:30.158995Z","iopub.execute_input":"2024-11-03T09:04:30.159753Z","iopub.status.idle":"2024-11-03T09:04:30.166754Z","shell.execute_reply.started":"2024-11-03T09:04:30.159692Z","shell.execute_reply":"2024-11-03T09:04:30.165816Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Below, we define the custom metrics: mean dice coefficient and mean F1 score(with beta=0.5) calculated across all the classes**</br>\n**Then, we create the train and evaluate function**","metadata":{}},{"cell_type":"code","source":"# Prepare Dataloaders\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn\n)\nval_dataloader = DataLoader(\n    val_dataset, shuffle=False, collate_fn=collate_fn\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:06:31.390736Z","iopub.execute_input":"2024-11-03T10:06:31.391144Z","iopub.status.idle":"2024-11-03T10:06:31.396649Z","shell.execute_reply.started":"2024-11-03T10:06:31.391106Z","shell.execute_reply":"2024-11-03T10:06:31.395737Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nfrom sklearn.metrics import fbeta_score\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef compute_dice_f1_for_classes(pred_map, gt_map, beta=0.5, num_classes=None):\n    \"\"\"\n    Computes the Dice Coefficient and F1 score for each class between the predicted segmentation map and the ground truth.\n\n    Args:\n    - pred_map (torch.Tensor): Predicted segmentation map of shape (H, W).\n    - gt_map (torch.Tensor): Ground truth segmentation map of shape (H, W).\n    - beta (float): The beta value to weigh precision more or less than recall in F1 score.\n    - num_classes (int, optional): The number of classes to calculate metrics for. If None, it is inferred from the maps.\n\n    Returns:\n    - dice_coeff (float): Mean Dice coefficient across classes.\n    - f1_score (float): Mean F1 score across classes with the given beta.\n    \"\"\"\n    if num_classes is None:\n        num_classes = max(pred_map.max().item(), gt_map.max().item()) + 1\n\n    dice_scores = []\n    f1_scores = []\n\n    for cls in range(num_classes):\n        # Create binary masks for the current class in both pred_map and gt_map\n        pred_cls_mask = (pred_map == cls).float()\n        gt_cls_mask = (gt_map == cls).float()\n\n        # Dice coefficient: 2 * intersection / (size of prediction + size of ground truth)\n        intersection = (pred_cls_mask * gt_cls_mask).sum()\n        dice_coeff = (2 * intersection) / (pred_cls_mask.sum() + gt_cls_mask.sum() + 1e-8)\n        # dice_scores.append(dice_coeff.item())\n\n        # F1 score: (1 + beta^2) * precision * recall / (beta^2 * precision + recall)\n        precision = intersection / (pred_cls_mask.sum() + 1e-8)\n        recall = intersection / (gt_cls_mask.sum() + 1e-8)\n        f1_score = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall + 1e-8)\n        # f1_scores.append(f1_score.item())\n        if dice_coeff.item() > 0:\n            dice_scores.append(dice_coeff.item())\n        if f1_score.item() > 0:\n            f1_scores.append(f1_score.item())\n\n    # Mean of Dice and F1 across classes\n    mean_dice = sum(dice_scores) / len(dice_scores) if dice_scores else 0.0\n    mean_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0.0\n\n    return mean_dice, mean_f1\n\n\ndef evaluate_model(\n    model: Mask2FormerForUniversalSegmentation,\n    dataloader: DataLoader,\n    preprocessor: AutoImageProcessor,\n    id2label: dict,\n    max_batches=None,\n\n):\n    \"\"\"\n    Evaluates the given model using the specified dataloader and computes a custom metric:\n    - Mean of Dice coefficient\n    - Mean of F1 score with beta=0.5\n    ----\n    Args:\n      - model (MaskFormerForInstanceSegmentation): The trained model to be evaluated.\n      - dataloader (DataLoader): DataLoader containing the dataset for evaluation.\n      - preprocessor (AutoImageProcessor): The preprocessor used for post-processing the model outputs.\n      - id2label (dict): Dictionary mapping class ids to their corresponding labels.\n      - max_batches (int, optional): Maximum number of batches to evaluate. If None, evaluates on the entire validation dataset.\n\n    Returns:\n    dict: The mean Dice coefficient and F1 score calculated over the specified number of batches.\n    \"\"\"\n    model.eval()\n    running_dice = 0.0\n    running_f1 = 0.0\n    num_batches = 0\n    with torch.no_grad():\n        for idx, batch in enumerate(tqdm(dataloader)):\n            #if max_batches and idx >= max_batches:\n             #   break\n            \n            pixel_values = batch[\"pixel_values\"].to(device)\n            outputs = model(pixel_values=pixel_values)\n\n            original_images = batch[\"original_images\"]\n            target_sizes = [\n                (image.shape[0], image.shape[1]) for image in original_images\n            ]\n\n            predicted_segmentation_maps = (\n                preprocessor.post_process_semantic_segmentation(\n                    outputs, target_sizes=target_sizes\n                )\n            )\n\n            ground_truth_segmentation_maps = batch[\"original_segmentation_maps\"]\n\n            # Iterate over the batch\n            for pred_map, gt_map in zip(predicted_segmentation_maps, ground_truth_segmentation_maps):\n                # Convert numpy arrays to torch tensors\n                pred_map = torch.tensor(pred_map).to(device)\n                gt_map = torch.tensor(gt_map).to(device)\n\n                # Compute mean dice and F1 score across all classes in the batch\n                dice_coeff, f1_score = compute_dice_f1_for_classes(pred_map, gt_map, beta=0.5)\n\n                running_dice += dice_coeff\n                running_f1 += f1_score\n                num_batches += 1\n\n    mean_dice = running_dice / num_batches\n    mean_f1 = running_f1 / num_batches\n\n    return {\"mean_dice\": mean_dice, \"mean_f1\": mean_f1}\n\n\ndef train_model(\n    train_loss,\n    model: Mask2FormerForUniversalSegmentation,\n    train_dataloader: DataLoader,\n    val_dataloader: DataLoader,\n    preprocessor: AutoImageProcessor,\n    id2label: dict,\n    num_epochs=100,\n    learning_rate=5e-5,\n    log_interval=100,\n    \n):\n    \"\"\"\n    Trains the Mask2Former model for semantic segmentation over a specified number of epochs and evaluates it on a validation set using custom metrics.\n    ----\n    Args:\n      - model (MaskFormerForInstanceSegmentation): The model to be trained.\n      - train_dataloader (DataLoader): DataLoader for the training data.\n      - val_dataloader (DataLoader): DataLoader for the validation data.\n      - preprocessor (AutoImageProcessor): The preprocessor used for preparing the data.\n      - id2label (dict): Dictionary mapping class IDs to their corresponding labels.\n      - num_epochs (int): Number of epochs to train the model.\n      - learning_rate (float): Learning rate for the optimizer.\n      - log_interval (int): Interval (in number of batches) at which to log training progress.\n\n    \"\"\"\n    model.to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\n    for epoch in range(num_epochs):\n        print(f\"Current epoch: {epoch+1}/{num_epochs}\")\n        model.train()\n\n        running_loss = 0.0\n        num_samples = 0\n\n        for idx, batch in enumerate(tqdm(train_dataloader)):\n            optimizer.zero_grad()\n            batch['class_labels'] = [torch.where(label == -1, torch.tensor(35), label) for label in batch['class_labels']]\n            outputs = model(\n                pixel_values=batch[\"pixel_values\"].to(device),\n                mask_labels=[labels.to(device) for labels in batch[\"mask_labels\"]],\n                class_labels=[labels.to(device) for labels in batch[\"class_labels\"]],\n            )\n\n            loss = outputs.loss\n            loss.backward()\n\n            batch_size = batch[\"pixel_values\"].size(0)\n            running_loss += loss.item()\n            num_samples += batch_size\n\n            if idx % log_interval == 0 and idx > 0:\n                print(f\"Iteration {idx} - loss: {running_loss/num_samples}\")\n\n            optimizer.step()\n        train_loss.append(running_loss/num_samples)\n        # Evaluate using the custom metric\n        val_metrics = evaluate_model(\n            model, val_dataloader, preprocessor, id2label, max_batches=6\n        )\n        print(f\"Validation Metrics - Mean Dice: {val_metrics['mean_dice']}, Mean F1 (β=0.5): {val_metrics['mean_f1']}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:06:31.680989Z","iopub.execute_input":"2024-11-03T10:06:31.681349Z","iopub.status.idle":"2024-11-03T10:06:31.70736Z","shell.execute_reply.started":"2024-11-03T10:06:31.681314Z","shell.execute_reply":"2024-11-03T10:06:31.706261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"AdamW_2_loss=[]\nAdamW_4_loss=[]\nAdamW_8_loss=[]\nAdamW_16_loss=[]\ntrain_model(\n    AdamW_8_loss,\n    model,\n    train_dataloader,\n    val_dataloader,\n    preprocessor,\n    id2label,\n    num_epochs=2,\n    log_interval=100,\n    \n)","metadata":{"id":"kWgT1tuDsF7h","outputId":"196708d3-f5c4-4629-f58e-a0967cf722be","execution":{"iopub.status.busy":"2024-11-03T09:05:55.685985Z","iopub.execute_input":"2024-11-03T09:05:55.686388Z","iopub.status.idle":"2024-11-03T09:22:04.100688Z","shell.execute_reply.started":"2024-11-03T09:05:55.686349Z","shell.execute_reply":"2024-11-03T09:22:04.099708Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"AdamW and 8 batches\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot([1,2],AdamW_8_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:29:06.552959Z","iopub.execute_input":"2024-11-03T09:29:06.553774Z","iopub.status.idle":"2024-11-03T09:29:06.855745Z","shell.execute_reply.started":"2024-11-03T09:29:06.553735Z","shell.execute_reply":"2024-11-03T09:29:06.854825Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#del(AdamW_8_loss)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T04:56:10.912229Z","iopub.execute_input":"2024-10-31T04:56:10.91319Z","iopub.status.idle":"2024-10-31T04:56:10.917372Z","shell.execute_reply.started":"2024-10-31T04:56:10.913144Z","shell.execute_reply":"2024-10-31T04:56:10.916485Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(\n    AdamW_2_loss,\n    model,\n    train_dataloader,\n    val_dataloader,\n    preprocessor,\n    id2label,\n    num_epochs=2,\n    log_interval=100,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:29:31.716906Z","iopub.execute_input":"2024-11-03T09:29:31.717923Z","iopub.status.idle":"2024-11-03T09:47:11.601961Z","shell.execute_reply.started":"2024-11-03T09:29:31.71788Z","shell.execute_reply":"2024-11-03T09:47:11.600656Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"AdamW and 2 batches\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot([1,2],AdamW_2_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:48:34.642745Z","iopub.execute_input":"2024-11-03T09:48:34.643487Z","iopub.status.idle":"2024-11-03T09:48:34.945815Z","shell.execute_reply.started":"2024-11-03T09:48:34.643442Z","shell.execute_reply":"2024-11-03T09:48:34.944833Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#del(AdamW_2_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:48:57.707337Z","iopub.execute_input":"2024-11-03T09:48:57.708101Z","iopub.status.idle":"2024-11-03T09:48:57.712056Z","shell.execute_reply.started":"2024-11-03T09:48:57.708062Z","shell.execute_reply":"2024-11-03T09:48:57.711024Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(\n    AdamW_4_loss,\n    model,\n    train_dataloader,\n    val_dataloader,\n    preprocessor,\n    id2label,\n    num_epochs=2,\n    log_interval=100,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:48:58.045203Z","iopub.execute_input":"2024-11-03T09:48:58.04575Z","iopub.status.idle":"2024-11-03T10:05:34.153354Z","shell.execute_reply.started":"2024-11-03T09:48:58.045689Z","shell.execute_reply":"2024-11-03T10:05:34.152493Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"AdamW and 4 batches\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot([1,2],AdamW_4_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:06:19.405524Z","iopub.execute_input":"2024-11-03T10:06:19.405912Z","iopub.status.idle":"2024-11-03T10:06:19.688037Z","shell.execute_reply.started":"2024-11-03T10:06:19.405876Z","shell.execute_reply":"2024-11-03T10:06:19.687028Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#del(AdamW_4_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:06:40.70874Z","iopub.execute_input":"2024-11-03T10:06:40.709142Z","iopub.status.idle":"2024-11-03T10:06:40.713618Z","shell.execute_reply.started":"2024-11-03T10:06:40.709107Z","shell.execute_reply":"2024-11-03T10:06:40.71251Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(\n    AdamW_16_loss,\n    model,\n    train_dataloader,\n    val_dataloader,\n    preprocessor,\n    id2label,\n    num_epochs=2,\n    log_interval=100,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:06:42.189464Z","iopub.execute_input":"2024-11-03T10:06:42.189873Z","iopub.status.idle":"2024-11-03T10:22:32.529866Z","shell.execute_reply.started":"2024-11-03T10:06:42.189831Z","shell.execute_reply":"2024-11-03T10:22:32.52874Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"AdamW and 16 batches\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot([1,2],AdamW_16_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:23:04.207601Z","iopub.execute_input":"2024-11-03T10:23:04.208502Z","iopub.status.idle":"2024-11-03T10:23:04.493854Z","shell.execute_reply.started":"2024-11-03T10:23:04.208459Z","shell.execute_reply":"2024-11-03T10:23:04.492937Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#del(AdamW_16_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:23:10.228535Z","iopub.execute_input":"2024-11-03T10:23:10.228956Z","iopub.status.idle":"2024-11-03T10:23:10.233616Z","shell.execute_reply.started":"2024-11-03T10:23:10.228916Z","shell.execute_reply":"2024-11-03T10:23:10.232393Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot([1,2],AdamW_2_loss,label='AdamW with batch size=2')\nplt.plot([1,2],AdamW_4_loss,label='AdamW with batch size=4')\nplt.plot([1,2],AdamW_8_loss,label='AdamW with batch size=8')\nplt.plot([1,2],AdamW_16_loss,label='AdamW with batch size=16')\nplt.legend(loc=\"lower right\")\nplt.title(\"AdamW\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:30:52.950309Z","iopub.execute_input":"2024-11-03T10:30:52.950706Z","iopub.status.idle":"2024-11-03T10:30:53.252993Z","shell.execute_reply.started":"2024-11-03T10:30:52.950667Z","shell.execute_reply":"2024-11-03T10:30:53.251971Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pixel level module contains both the backbone and the pixel decoder\nfor param in model.model.pixel_level_module.parameters():\n    param.requires_grad = False\n\n# Confirm that the parameters are correctly frozen\nfor name, param in model.model.pixel_level_module.named_parameters():\n    assert not param.requires_grad","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:35:20.940112Z","iopub.execute_input":"2024-11-03T11:35:20.941139Z","iopub.status.idle":"2024-11-03T11:35:20.951803Z","shell.execute_reply.started":"2024-11-03T11:35:20.941095Z","shell.execute_reply":"2024-11-03T11:35:20.950956Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare Dataloaders\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn\n)\nval_dataloader = DataLoader(\n    val_dataset, shuffle=False, collate_fn=collate_fn\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:35:22.209163Z","iopub.execute_input":"2024-11-03T11:35:22.210089Z","iopub.status.idle":"2024-11-03T11:35:22.215269Z","shell.execute_reply.started":"2024-11-03T11:35:22.210048Z","shell.execute_reply":"2024-11-03T11:35:22.214306Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_dice_f1_for_classes(pred_map, gt_map, beta=0.5, num_classes=None):\n    \"\"\"\n    Computes the Dice Coefficient and F1 score for each class between the predicted segmentation map and the ground truth.\n\n    Args:\n    - pred_map (torch.Tensor): Predicted segmentation map of shape (H, W).\n    - gt_map (torch.Tensor): Ground truth segmentation map of shape (H, W).\n    - beta (float): The beta value to weigh precision more or less than recall in F1 score.\n    - num_classes (int, optional): The number of classes to calculate metrics for. If None, it is inferred from the maps.\n\n    Returns:\n    - dice_coeff (float): Mean Dice coefficient across classes.\n    - f1_score (float): Mean F1 score across classes with the given beta.\n    \"\"\"\n    if num_classes is None:\n        num_classes = max(pred_map.max().item(), gt_map.max().item()) + 1\n\n    dice_scores = []\n    f1_scores = []\n\n    for cls in range(num_classes):\n        # Create binary masks for the current class in both pred_map and gt_map\n        pred_cls_mask = (pred_map == cls).float()\n        gt_cls_mask = (gt_map == cls).float()\n\n        # Dice coefficient: 2 * intersection / (size of prediction + size of ground truth)\n        intersection = (pred_cls_mask * gt_cls_mask).sum()\n        dice_coeff = (2 * intersection) / (pred_cls_mask.sum() + gt_cls_mask.sum() + 1e-8)\n        # dice_scores.append(dice_coeff.item())\n\n        # F1 score: (1 + beta^2) * precision * recall / (beta^2 * precision + recall)\n        precision = intersection / (pred_cls_mask.sum() + 1e-8)\n        recall = intersection / (gt_cls_mask.sum() + 1e-8)\n        f1_score = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall + 1e-8)\n        # f1_scores.append(f1_score.item())\n        if dice_coeff.item() > 0:\n            dice_scores.append(dice_coeff.item())\n        if f1_score.item() > 0:\n            f1_scores.append(f1_score.item())\n\n    # Mean of Dice and F1 across classes\n    mean_dice = sum(dice_scores) / len(dice_scores) if dice_scores else 0.0\n    mean_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0.0\n\n    return mean_dice, mean_f1\n\n\ndef evaluate_model(\n    model: Mask2FormerForUniversalSegmentation,\n    dataloader: DataLoader,\n    preprocessor: AutoImageProcessor,\n    id2label: dict,\n    max_batches=None,\n\n):\n    \"\"\"\n    Evaluates the given model using the specified dataloader and computes a custom metric:\n    - Mean of Dice coefficient\n    - Mean of F1 score with beta=0.5\n    ----\n    Args:\n      - model (MaskFormerForInstanceSegmentation): The trained model to be evaluated.\n      - dataloader (DataLoader): DataLoader containing the dataset for evaluation.\n      - preprocessor (AutoImageProcessor): The preprocessor used for post-processing the model outputs.\n      - id2label (dict): Dictionary mapping class ids to their corresponding labels.\n      - max_batches (int, optional): Maximum number of batches to evaluate. If None, evaluates on the entire validation dataset.\n\n    Returns:\n    dict: The mean Dice coefficient and F1 score calculated over the specified number of batches.\n    \"\"\"\n    model.eval()\n    running_dice = 0.0\n    running_f1 = 0.0\n    num_batches = 0\n    with torch.no_grad():\n        for idx, batch in enumerate(tqdm(dataloader)):\n            #if max_batches and idx >= max_batches:\n             #   break\n            \n            pixel_values = batch[\"pixel_values\"].to(device)\n            outputs = model(pixel_values=pixel_values)\n\n            original_images = batch[\"original_images\"]\n            target_sizes = [\n                (image.shape[0], image.shape[1]) for image in original_images\n            ]\n\n            predicted_segmentation_maps = (\n                preprocessor.post_process_semantic_segmentation(\n                    outputs, target_sizes=target_sizes\n                )\n            )\n\n            ground_truth_segmentation_maps = batch[\"original_segmentation_maps\"]\n\n            # Iterate over the batch\n            for pred_map, gt_map in zip(predicted_segmentation_maps, ground_truth_segmentation_maps):\n                # Convert numpy arrays to torch tensors\n                pred_map = torch.tensor(pred_map).to(device)\n                gt_map = torch.tensor(gt_map).to(device)\n\n                # Compute mean dice and F1 score across all classes in the batch\n                dice_coeff, f1_score = compute_dice_f1_for_classes(pred_map, gt_map, beta=0.5)\n\n                running_dice += dice_coeff\n                running_f1 += f1_score\n                num_batches += 1\n\n    mean_dice = running_dice / num_batches\n    mean_f1 = running_f1 / num_batches\n\n    return {\"mean_dice\": mean_dice, \"mean_f1\": mean_f1}\n\n\ndef train_model(\n    train_loss,\n    model: Mask2FormerForUniversalSegmentation,\n    train_dataloader: DataLoader,\n    val_dataloader: DataLoader,\n    preprocessor: AutoImageProcessor,\n    id2label: dict,\n    num_epochs=100,\n    learning_rate=5e-5,\n    log_interval=100,\n    \n):\n    \"\"\"\n    Trains the Mask2Former model for semantic segmentation over a specified number of epochs and evaluates it on a validation set using custom metrics.\n    ----\n    Args:\n      - model (MaskFormerForInstanceSegmentation): The model to be trained.\n      - train_dataloader (DataLoader): DataLoader for the training data.\n      - val_dataloader (DataLoader): DataLoader for the validation data.\n      - preprocessor (AutoImageProcessor): The preprocessor used for preparing the data.\n      - id2label (dict): Dictionary mapping class IDs to their corresponding labels.\n      - num_epochs (int): Number of epochs to train the model.\n      - learning_rate (float): Learning rate for the optimizer.\n      - log_interval (int): Interval (in number of batches) at which to log training progress.\n\n    \"\"\"\n    model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n    for epoch in range(num_epochs):\n        print(f\"Current epoch: {epoch+1}/{num_epochs}\")\n        model.train()\n\n        running_loss = 0.0\n        num_samples = 0\n\n        for idx, batch in enumerate(tqdm(train_dataloader)):\n            optimizer.zero_grad()\n            batch['class_labels'] = [torch.where(label == -1, torch.tensor(35), label) for label in batch['class_labels']]\n            outputs = model(\n                pixel_values=batch[\"pixel_values\"].to(device),\n                mask_labels=[labels.to(device) for labels in batch[\"mask_labels\"]],\n                class_labels=[labels.to(device) for labels in batch[\"class_labels\"]],\n            )\n\n            loss = outputs.loss\n            loss.backward()\n\n            batch_size = batch[\"pixel_values\"].size(0)\n            running_loss += loss.item()\n            num_samples += batch_size\n\n            if idx % log_interval == 0 and idx > 0:\n                print(f\"Iteration {idx} - loss: {running_loss/num_samples}\")\n\n            optimizer.step()\n        train_loss.append(running_loss/num_samples)\n        # Evaluate using the custom metric\n        val_metrics = evaluate_model(\n            model, val_dataloader, preprocessor, id2label, max_batches=6\n        )\n        print(f\"Validation Metrics - Mean Dice: {val_metrics['mean_dice']}, Mean F1 (β=0.5): {val_metrics['mean_f1']}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:35:23.460656Z","iopub.execute_input":"2024-11-03T11:35:23.461033Z","iopub.status.idle":"2024-11-03T11:35:23.485299Z","shell.execute_reply.started":"2024-11-03T11:35:23.460997Z","shell.execute_reply":"2024-11-03T11:35:23.48443Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Adam_2_loss=[]\nAdam_4_loss=[]\nAdam_8_loss=[]\nAdam_16_loss=[]\ntrain_model(\n    Adam_8_loss,\n    model,\n    train_dataloader,\n    val_dataloader,\n    preprocessor,\n    id2label,\n    num_epochs=2,\n    log_interval=100,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:32:29.683065Z","iopub.execute_input":"2024-11-03T10:32:29.683778Z","iopub.status.idle":"2024-11-03T10:48:33.559369Z","shell.execute_reply.started":"2024-11-03T10:32:29.683738Z","shell.execute_reply":"2024-11-03T10:48:33.558292Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"Adam with 8 batches\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot([1,2],Adam_8_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:55:00.411374Z","iopub.execute_input":"2024-11-03T10:55:00.411771Z","iopub.status.idle":"2024-11-03T10:55:00.704147Z","shell.execute_reply.started":"2024-11-03T10:55:00.411735Z","shell.execute_reply":"2024-11-03T10:55:00.703174Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#del(Adam_8_loss)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:24:17.354882Z","iopub.execute_input":"2024-10-31T06:24:17.355632Z","iopub.status.idle":"2024-10-31T06:24:17.359849Z","shell.execute_reply.started":"2024-10-31T06:24:17.355591Z","shell.execute_reply":"2024-10-31T06:24:17.358796Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(\n    Adam_2_loss,\n    model,\n    train_dataloader,\n    val_dataloader,\n    preprocessor,\n    id2label,\n    num_epochs=2,\n    log_interval=100,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:55:20.401549Z","iopub.execute_input":"2024-11-03T10:55:20.4022Z","iopub.status.idle":"2024-11-03T11:13:04.771073Z","shell.execute_reply.started":"2024-11-03T10:55:20.402159Z","shell.execute_reply":"2024-11-03T11:13:04.769942Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"Adam with 2 batches\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot([1,2],Adam_2_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:14:11.592623Z","iopub.execute_input":"2024-11-03T11:14:11.593509Z","iopub.status.idle":"2024-11-03T11:14:11.868667Z","shell.execute_reply.started":"2024-11-03T11:14:11.593464Z","shell.execute_reply":"2024-11-03T11:14:11.867726Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#del(Adam_2_loss)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:44:02.563725Z","iopub.execute_input":"2024-10-31T06:44:02.564403Z","iopub.status.idle":"2024-10-31T06:44:02.568854Z","shell.execute_reply.started":"2024-10-31T06:44:02.564355Z","shell.execute_reply":"2024-10-31T06:44:02.567736Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(\n    Adam_4_loss,\n    model,\n    train_dataloader,\n    val_dataloader,\n    preprocessor,\n    id2label,\n    num_epochs=2,\n    log_interval=100,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:18:27.876259Z","iopub.execute_input":"2024-11-03T11:18:27.87667Z","iopub.status.idle":"2024-11-03T11:34:58.800437Z","shell.execute_reply.started":"2024-11-03T11:18:27.876629Z","shell.execute_reply":"2024-11-03T11:34:58.799409Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"Adam with 4 batches\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot([1,2],Adam_4_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:35:01.156679Z","iopub.execute_input":"2024-11-03T11:35:01.157381Z","iopub.status.idle":"2024-11-03T11:35:01.399992Z","shell.execute_reply.started":"2024-11-03T11:35:01.157341Z","shell.execute_reply":"2024-11-03T11:35:01.398975Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#del(Adam_4_loss)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T07:08:14.724539Z","iopub.execute_input":"2024-10-31T07:08:14.725457Z","iopub.status.idle":"2024-10-31T07:08:14.729498Z","shell.execute_reply.started":"2024-10-31T07:08:14.725416Z","shell.execute_reply":"2024-10-31T07:08:14.728484Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(\n    Adam_16_loss,\n    model,\n    train_dataloader,\n    val_dataloader,\n    preprocessor,\n    id2label,\n    num_epochs=2,\n    log_interval=100,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:35:29.319639Z","iopub.execute_input":"2024-11-03T11:35:29.320552Z","iopub.status.idle":"2024-11-03T11:51:21.093104Z","shell.execute_reply.started":"2024-11-03T11:35:29.320512Z","shell.execute_reply":"2024-11-03T11:51:21.092141Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"Adam with 16 batches\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot([1,2],Adam_16_loss)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:51:23.763485Z","iopub.execute_input":"2024-11-03T11:51:23.764681Z","iopub.status.idle":"2024-11-03T11:51:24.044146Z","shell.execute_reply.started":"2024-11-03T11:51:23.764628Z","shell.execute_reply":"2024-11-03T11:51:24.043204Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot([1,2],Adam_2_loss,label='Adam with batch size=2')\nplt.plot([1,2],Adam_4_loss,label='Adam with batch size=4')\nplt.plot([1,2],Adam_8_loss,label='Adam with batch size=8')\nplt.plot([1,2],Adam_16_loss,label='Adam with batch size=16')\nplt.legend(loc=\"lower right\")\nplt.title(\"Adam\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T11:52:05.531023Z","iopub.execute_input":"2024-11-03T11:52:05.531412Z","iopub.status.idle":"2024-11-03T11:52:05.818844Z","shell.execute_reply.started":"2024-11-03T11:52:05.531375Z","shell.execute_reply":"2024-11-03T11:52:05.817905Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Test Evaluation**","metadata":{}},{"cell_type":"code","source":"test_metric = evaluate_model(model, test_dataloader, preprocessor, id2label)\nprint(f\"Validation Metrics - Mean Dice: {test_metric['mean_dice']}, Mean F1 (β=0.5): {test_metric['mean_f1']}\")","metadata":{"id":"AG4jhtsRV8qq","outputId":"a39b6bca-8928-4dcd-e4a4-db463b3b0833","execution":{"iopub.status.busy":"2024-10-29T17:30:21.312486Z","iopub.execute_input":"2024-10-29T17:30:21.313366Z","iopub.status.idle":"2024-10-29T17:31:25.587979Z","shell.execute_reply.started":"2024-10-29T17:30:21.313324Z","shell.execute_reply":"2024-10-29T17:31:25.587068Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tloss","metadata":{"execution":{"iopub.status.busy":"2024-10-29T17:31:53.687702Z","iopub.execute_input":"2024-10-29T17:31:53.688086Z","iopub.status.idle":"2024-10-29T17:31:53.73429Z","shell.execute_reply.started":"2024-10-29T17:31:53.68805Z","shell.execute_reply":"2024-10-29T17:31:53.732999Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_inference_samples(\n    model: Mask2FormerForUniversalSegmentation,\n    dataloader: DataLoader,\n    preprocessor: AutoImageProcessor,\n    n: int = 5,\n):\n    \"\"\"\n    Displays 'n' samples from the dataloader with model inference results.\n    ----\n    Args:\n     - model: The trained model.\n     - dataloader: DataLoader containing the dataset for inference.\n     - preprocessor: The preprocessor used for post-processing the outputs.\n     - n (int): Number of samples to display.\n\n    \"\"\"\n    model.to(device)\n    model.eval()\n\n    if n > len(dataloader.dataset):\n        raise ValueError(\"n is larger than the dataset size\")\n\n    fig, axs = plt.subplots(n, 2, figsize=(10, 5 * n))\n\n    with torch.no_grad():\n        for i, batch in enumerate(dataloader):\n            if i >= n:\n                break\n\n            pixel_values = batch[\"pixel_values\"].to(device)\n            outputs = model(pixel_values=pixel_values)\n\n            original_images = batch[\"original_images\"]\n            target_sizes = [\n                (image.shape[0], image.shape[1]) for image in original_images\n            ]\n            predicted_segmentation_maps = (\n                preprocessor.post_process_semantic_segmentation(\n                    outputs, target_sizes=target_sizes\n                )\n            )\n\n            ground_truth_segmentation_maps = batch[\"original_segmentation_maps\"]\n\n            # Assuming original_images are numpy arrays and already in the right format\n            image = original_images[i]\n            ground_truth_map = ground_truth_segmentation_maps[i]\n            predicted_map = predicted_segmentation_maps[i]\n\n            axs[i, 0].imshow(image)\n            axs[i, 0].imshow(ground_truth_map, cmap=\"nipy_spectral\", alpha=0.5)\n            axs[i, 0].set_title(\"Ground Truth\")\n            axs[i, 0].axis(\"off\")\n\n            axs[i, 1].imshow(image)\n            axs[i, 1].imshow(\n                predicted_map.cpu().numpy(), cmap=\"nipy_spectral\", alpha=0.5\n            )\n            axs[i, 1].set_title(\"Prediction\")\n            axs[i, 1].axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"7_E6409tPtDv","execution":{"iopub.status.busy":"2024-10-10T11:06:38.679848Z","iopub.execute_input":"2024-10-10T11:06:38.680835Z","iopub.status.idle":"2024-10-10T11:06:38.692554Z","shell.execute_reply.started":"2024-10-10T11:06:38.680791Z","shell.execute_reply":"2024-10-10T11:06:38.691493Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_inference_samples(model, test_dataloader, preprocessor, n=2)","metadata":{"id":"E-oIk4MX-99p","outputId":"3aacd388-3ca6-4878-ca84-2ebb0421fbf4","execution":{"iopub.status.busy":"2024-10-10T11:06:41.573576Z","iopub.execute_input":"2024-10-10T11:06:41.574649Z","iopub.status.idle":"2024-10-10T11:06:52.034924Z","shell.execute_reply.started":"2024-10-10T11:06:41.574606Z","shell.execute_reply":"2024-10-10T11:06:52.033914Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.mkdir('finetuned')","metadata":{"execution":{"iopub.status.busy":"2024-10-10T11:13:10.318352Z","iopub.execute_input":"2024-10-10T11:13:10.318773Z","iopub.status.idle":"2024-10-10T11:13:10.323727Z","shell.execute_reply.started":"2024-10-10T11:13:10.318735Z","shell.execute_reply":"2024-10-10T11:13:10.322767Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"finetuned\")","metadata":{"execution":{"iopub.status.busy":"2024-10-10T11:13:33.043841Z","iopub.execute_input":"2024-10-10T11:13:33.044258Z","iopub.status.idle":"2024-10-10T11:13:35.89289Z","shell.execute_reply.started":"2024-10-10T11:13:33.04422Z","shell.execute_reply":"2024-10-10T11:13:35.89168Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r finetuned.zip finetuned/","metadata":{"execution":{"iopub.status.busy":"2024-10-10T11:15:31.471732Z","iopub.execute_input":"2024-10-10T11:15:31.472767Z","iopub.status.idle":"2024-10-10T11:16:20.55826Z","shell.execute_reply.started":"2024-10-10T11:15:31.472719Z","shell.execute_reply":"2024-10-10T11:16:20.557089Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"test_dir = '/kaggle/input/iitg-ai-overnight-hackathon-2024/dataset/dataset/test'\n# Array to store the dataset\ntest_dataset = []\n\ntest_images = [f for f in os.listdir(test_dir) if f.endswith('.jpg')]\nfor test_image in test_images:\n    filename = test_image.split('_')[0]\n    image_path = os.path.join(test_dir, test_image)\n    pixel_image = Image.open(image_path).resize((512,512))\n    test_dataset.append({'pixel_values': pixel_image,\n                         'id' : filename})\n\n# Example to show the contents of data_set\nfor idx, data in enumerate(test_dataset[:3]):  # Show first 3 entries\n    print(f\"Index {idx}:\")\n    print(f\"Pixels Image: {data['pixel_values']}\")\n    print(f\"ID: {data['id']}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:34:42.708927Z","iopub.execute_input":"2024-10-12T12:34:42.709418Z","iopub.status.idle":"2024-10-12T12:34:46.880737Z","shell.execute_reply.started":"2024-10-12T12:34:42.709369Z","shell.execute_reply":"2024-10-12T12:34:46.879799Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_images[0].split('_')[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:34:50.000982Z","iopub.execute_input":"2024-10-12T12:34:50.001677Z","iopub.status.idle":"2024-10-12T12:34:50.007852Z","shell.execute_reply.started":"2024-10-12T12:34:50.001637Z","shell.execute_reply":"2024-10-12T12:34:50.006821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_images","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:17:21.342765Z","iopub.execute_input":"2024-10-10T15:17:21.343526Z","iopub.status.idle":"2024-10-10T15:17:21.351575Z","shell.execute_reply.started":"2024-10-10T15:17:21.343484Z","shell.execute_reply":"2024-10-10T15:17:21.350688Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\ntest_ds = Dataset.from_dict({\"pixel_values\": [item[\"pixel_values\"] for item in test_dataset],\n                            \"id\": [item[\"id\"] for item in test_dataset]})","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:34:55.604861Z","iopub.execute_input":"2024-10-12T12:34:55.605597Z","iopub.status.idle":"2024-10-12T12:35:09.798453Z","shell.execute_reply.started":"2024-10-12T12:34:55.605552Z","shell.execute_reply":"2024-10-12T12:35:09.797453Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ds","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:35:09.800086Z","iopub.execute_input":"2024-10-12T12:35:09.800403Z","iopub.status.idle":"2024-10-12T12:35:09.806241Z","shell.execute_reply.started":"2024-10-12T12:35:09.800371Z","shell.execute_reply":"2024-10-12T12:35:09.805338Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id2label","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:20:42.707868Z","iopub.execute_input":"2024-10-10T15:20:42.708302Z","iopub.status.idle":"2024-10-10T15:20:42.720311Z","shell.execute_reply.started":"2024-10-10T15:20:42.708266Z","shell.execute_reply":"2024-10-10T15:20:42.719483Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = test_ds[0]['pixel_values']\nplt.imshow(sample)\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:35:14.85382Z","iopub.execute_input":"2024-10-12T12:35:14.854182Z","iopub.status.idle":"2024-10-12T12:35:15.134307Z","shell.execute_reply.started":"2024-10-12T12:35:14.854148Z","shell.execute_reply":"2024-10-12T12:35:15.133452Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Loading the finetuned model**","metadata":{}},{"cell_type":"code","source":"model = Mask2FormerForUniversalSegmentation.from_pretrained(\"/kaggle/input/mask-fine\")","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:35:18.879987Z","iopub.execute_input":"2024-10-12T12:35:18.880812Z","iopub.status.idle":"2024-10-12T12:35:20.439863Z","shell.execute_reply.started":"2024-10-12T12:35:18.880774Z","shell.execute_reply":"2024-10-12T12:35:20.439109Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom dataclasses import dataclass\nimport numpy as np\nfrom typing import Any, List\nfrom transformers import Mask2FormerImageProcessor\n\npreprocessor = Mask2FormerImageProcessor(\n    ignore_index=0,\n    do_reduce_labels=False,\n    do_resize=False,\n    do_rescale=False,\n    do_normalize=False,\n)\n\nade_mean = [123.675 / 255, 116.280 / 255, 103.530 / 255]\nade_std = [58.395 / 255, 57.120 / 255, 57.375 / 255]\n\nclass TestSegmentationTransform:\n    def __init__(self):\n        self.img_transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=ade_mean, std=ade_std)\n        ])\n\n    def __call__(self, image):\n        return self.img_transform(image)\n\n@dataclass\nclass TestSegmentationDataInput:\n    image_id: str\n    original_image: np.ndarray\n    transformed_image: torch.Tensor\n\nclass TestSemanticSegmentationDataset(Dataset):\n    def __init__(self, dataset: Any) -> None:\n        \"\"\"\n        Dataset for Semantic Segmentation Testing.\n        ----\n        Args:\n          - dataset: A dataset containing images for prediction.\n        \"\"\"\n        self.dataset = dataset\n        self.transform = TestSegmentationTransform()\n\n    def __len__(self) -> int:\n        return len(self.dataset)\n\n    def __getitem__(self, idx: int) -> TestSegmentationDataInput:\n        sample = self.dataset[idx]\n        original_image = sample[\"pixel_values\"]\n        image_id = sample[\"id\"]  # Assuming the ID is stored under the key \"id\"\n        \n        transformed_image = self.transform(original_image)\n        \n        return TestSegmentationDataInput(\n            image_id=image_id,\n            original_image=np.array(original_image),\n            transformed_image=transformed_image,\n        )\n\ndef test_collate_fn(batch: List[TestSegmentationDataInput]) -> dict:\n    image_ids = [sample.image_id for sample in batch]\n    original_images = [sample.original_image for sample in batch]\n    transformed_images = [sample.transformed_image for sample in batch]\n\n    preprocessed_batch = preprocessor(\n        transformed_images,\n        return_tensors=\"pt\",\n    )\n    preprocessed_batch[\"image_id\"] = image_ids\n    preprocessed_batch[\"original_images\"] = original_images\n    return preprocessed_batch\n\n# Prepare Test Dataset\ntest_dataset = TestSemanticSegmentationDataset(test_ds)\n\n# Prepare Test Dataloader\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=8, shuffle=False, collate_fn=test_collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:35:28.5475Z","iopub.execute_input":"2024-10-12T12:35:28.547916Z","iopub.status.idle":"2024-10-12T12:35:28.563859Z","shell.execute_reply.started":"2024-10-12T12:35:28.547878Z","shell.execute_reply":"2024-10-12T12:35:28.562911Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ds","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:35:26.052048Z","iopub.execute_input":"2024-10-12T12:35:26.05238Z","iopub.status.idle":"2024-10-12T12:35:26.058445Z","shell.execute_reply.started":"2024-10-12T12:35:26.052347Z","shell.execute_reply":"2024-10-12T12:35:26.057446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in test_dataloader:\n    print(i.keys())\n    break","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:35:32.033348Z","iopub.execute_input":"2024-10-12T12:35:32.033712Z","iopub.status.idle":"2024-10-12T12:35:32.196441Z","shell.execute_reply.started":"2024-10-12T12:35:32.033679Z","shell.execute_reply":"2024-10-12T12:35:32.195432Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Below, we create the inference pipeline to make the model predict the segmentation maps and then convert them into image format and store in the output directory**","metadata":{}},{"cell_type":"code","source":"# import torch\n# from torch.utils.data import DataLoader\n# from transformers import MaskFormerForInstanceSegmentation, AutoImageProcessor\n# import numpy as np\n# import os\n# from tqdm import tqdm\n# import cv2\n\nlabel_to_color = {label.id: label.color for label in labels_details}\n\ndef run_inference_and_store(\n    model: Mask2FormerForUniversalSegmentation,\n    dataloader: DataLoader,\n    preprocessor: AutoImageProcessor,\n    output_dir: str,\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n):\n    \"\"\"\n    Runs inference on the test dataset and stores the predicted segmentation maps as color-coded images.\n    Returns a dictionary mapping image IDs to their file paths.\n    \"\"\"\n    model.to(device)\n    model.eval()\n    os.makedirs(output_dir, exist_ok=True)\n    \n    id_to_filepath = {}\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Running inference\"):\n            pixel_values = batch[\"pixel_values\"].to(device)\n            image_ids = batch[\"image_id\"]\n            outputs = model(pixel_values=pixel_values)\n            original_images = batch[\"original_images\"]\n            target_sizes = [(image.shape[0], image.shape[1]) for image in original_images]\n            predicted_segmentation_maps = preprocessor.post_process_semantic_segmentation(\n                outputs, target_sizes=target_sizes\n            )\n\n            for predicted_map, original_image, image_id in zip(predicted_segmentation_maps, original_images, image_ids):\n                predicted_map_np = predicted_map.cpu().numpy()\n                \n                # Create a color-coded image\n                color_map = np.zeros((predicted_map_np.shape[0], predicted_map_np.shape[1], 3), dtype=np.uint8)\n                for label_id, color in label_to_color.items():\n                    color_map[predicted_map_np == label_id] = color\n\n                # Save the color-coded image using image_id as the filename\n                filename = f\"{image_id}.png\"\n                filepath = os.path.join(output_dir, filename)\n                cv2.imwrite(filepath, cv2.cvtColor(color_map, cv2.COLOR_RGB2BGR))\n                \n                # Store the mapping of image ID to file path\n                id_to_filepath[image_id] = filepath\n\n    print(f\"Predicted segmentation maps saved as color-coded images in {output_dir}\")\n    return id_to_filepath\n# Usage example:\n# model = MaskFormerForInstanceSegmentation.from_pretrained(\"your_model_path\")\n# preprocessor = AutoImageProcessor.from_pretrained(\"your_model_path\")\noutput_dir = \"inference\"\nrun_inference_and_store(model=model, dataloader=test_dataloader, preprocessor=preprocessor, output_dir=output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:38:53.318737Z","iopub.execute_input":"2024-10-12T12:38:53.319377Z","iopub.status.idle":"2024-10-12T12:39:22.237554Z","shell.execute_reply.started":"2024-10-12T12:38:53.319338Z","shell.execute_reply":"2024-10-12T12:39:22.23664Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Script for getting the submission csv file from the inferred segmentation maps**</br>\n**Here, we modify the script a bit to scale the predicted polygons for the expected image resolution i.e. 1920x1080 instead of our model output image res i.e. 512x512**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport json\nimport os\n\n\nclass Label:\n    def __init__(self, name, id, csId, csTrainId, level4id, level3Id, category, level2Id, level1Id, hasInstances, ignoreInEval, color):\n        self.name = name\n        self.id = id\n        self.csId = csId\n        self.csTrainId = csTrainId\n        self.level4id = level4id\n        self.level3Id = level3Id\n        self.category = category\n        self.level2Id = level2Id\n        self.level1Id = level1Id\n        self.hasInstances = hasInstances\n        self.ignoreInEval = ignoreInEval\n        self.color = color\n\n# Your label definitions here (from your provided list)\n\nlabels = [\n    #       name                     id    csId     csTrainId level4id        level3Id  category           level2Id      level1Id  hasInstances   ignoreInEval   color\n    Label(  'road'                 ,  0   ,  7 ,     0 ,       0   ,     0  ,   'drivable'            , 0           , 0      , False        , False        , (128, 64,128)  ),\n    Label(  'parking'              ,  1   ,  9 ,   255 ,       1   ,     1  ,   'drivable'            , 1           , 0      , False        , False         , (250,170,160)  ),\n    Label(  'drivable fallback'    ,  2   ,  255 ,   255 ,     2   ,       1  ,   'drivable'            , 1           , 0      , False        , False         , ( 81,  0, 81)  ),\n    Label(  'sidewalk'             ,  3   ,  8 ,     1 ,       3   ,     2  ,   'non-drivable'        , 2           , 1      , False        , False        , (244, 35,232)  ),\n    Label(  'rail track'           ,  4   , 10 ,   255 ,       3   ,     3  ,   'non-drivable'        , 3           , 1      , False        , False         , (230,150,140)  ),\n    Label(  'non-drivable fallback',  5   , 255 ,     9 ,      4   ,      3  ,   'non-drivable'        , 3           , 1      , False        , False        , (152,251,152)  ),\n    Label(  'person'               ,  6   , 24 ,    11 ,       5   ,     4  ,   'living-thing'        , 4           , 2      , True         , False        , (220, 20, 60)  ),\n    Label(  'animal'               ,  7   , 255 ,   255 ,      6   ,      4  ,   'living-thing'        , 4           , 2      , True         , True        , (246, 198, 145)),\n    Label(  'rider'                ,  8   , 25 ,    12 ,       7   ,     5  ,   'living-thing'        , 5           , 2      , True         , False        , (255,  0,  0)  ),\n    Label(  'motorcycle'           ,  9   , 32 ,    17 ,       8   ,     6  ,   '2-wheeler'           , 6           , 3      , True         , False        , (  0,  0,230)  ),\n    Label(  'bicycle'              , 10   , 33 ,    18 ,       9   ,     7  ,   '2-wheeler'           , 6           , 3      , True         , False        , (119, 11, 32)  ),\n    Label(  'autorickshaw'         , 11   , 255 ,   255 ,     10   ,      8  ,   'autorickshaw'        , 7           , 3      , True         , False        , (255, 204, 54) ),\n    Label(  'car'                  , 12   , 26 ,    13 ,      11   ,     9  ,   'car'                 , 7           , 3      , True         , False        , (  0,  0,142)  ),\n    Label(  'truck'                , 13   , 27 ,    14 ,      12   ,     10 ,   'large-vehicle'       , 8           , 3      , True         , False        , (  0,  0, 70)  ),\n    Label(  'bus'                  , 14   , 28 ,    15 ,      13   ,     11 ,   'large-vehicle'       , 8           , 3      , True         , False        , (  0, 60,100)  ),\n    Label(  'caravan'              , 15   , 29 ,   255 ,      14   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True         , (  0,  0, 90)  ),\n    Label(  'trailer'              , 16   , 30 ,   255 ,      15   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True         , (  0,  0,110)  ),\n    Label(  'train'                , 17   , 31 ,    16 ,      15   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True        , (  0, 80,100)  ),\n    Label(  'vehicle fallback'     , 18   , 355 ,   255 ,     15   ,      12 ,   'large-vehicle'       , 8           , 3      , True         , False        , (136, 143, 153)),  \n    Label(  'curb'                 , 19   ,255 ,   255 ,      16   ,     13 ,   'barrier'             , 9           , 4      , False        , False        , (220, 190, 40)),\n    Label(  'wall'                 , 20   , 12 ,     3 ,      17   ,     14 ,   'barrier'             , 9           , 4      , False        , False        , (102,102,156)  ),\n    Label(  'fence'                , 21   , 13 ,     4 ,      18   ,     15 ,   'barrier'             , 10           , 4      , False        , False        , (190,153,153)  ),\n    Label(  'guard rail'           , 22   , 14 ,   255 ,      19   ,     16 ,   'barrier'             , 10          , 4      , False        , False         , (180,165,180)  ),\n    Label(  'billboard'            , 23   , 255 ,   255 ,     20   ,      17 ,   'structures'          , 11           , 4      , False        , False        , (174, 64, 67) ),\n    Label(  'traffic sign'         , 24   , 20 ,     7 ,      21   ,     18 ,   'structures'          , 11          , 4      , False        , False        , (220,220,  0)  ),\n    Label(  'traffic light'        , 25   , 19 ,     6 ,      22   ,     19 ,   'structures'          , 11          , 4      , False        , False        , (250,170, 30)  ),\n    Label(  'pole'                 , 26   , 17 ,     5 ,      23   ,     20 ,   'structures'          , 12          , 4      , False        , False        , (153,153,153)  ),\n    Label(  'polegroup'            , 27   , 18 ,   255 ,      23   ,     20 ,   'structures'          , 12          , 4      , False        , False         , (153,153,153)  ),\n    Label(  'obs-str-bar-fallback' , 28   , 255 ,   255 ,     24   ,      21 ,   'structures'          , 12          , 4      , False        , False        , (169, 187, 214) ),  \n    Label(  'building'             , 29   , 11 ,     2 ,      25   ,     22 ,   'construction'        , 13          , 5      , False        , False        , ( 70, 70, 70)  ),\n    Label(  'bridge'               , 30   , 15 ,   255 ,      26   ,     23 ,   'construction'        , 13          , 5      , False        , False         , (150,100,100)  ),\n    Label(  'tunnel'               , 31   , 16 ,   255 ,      26   ,     23 ,   'construction'        , 13          , 5      , False        , False         , (150,120, 90)  ),\n    Label(  'vegetation'           , 32   , 21 ,     8 ,      27   ,     24 ,   'vegetation'          , 14          , 5      , False        , False        , (107,142, 35)  ),\n    Label(  'sky'                  , 33   , 23 ,    10 ,      28   ,     25 ,   'sky'                 , 15          , 6      , False        , False        , ( 70,130,180)  ),\n    Label(  'fallback background'  , 34   , 255 ,   255 ,     29   ,      25 ,   'object fallback'     , 15          , 6      , False        , False        , (169, 187, 214)),\n    Label(  'unlabeled'            , 35   ,  0  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n    Label(  'ego vehicle'          , 36   ,  1  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n    Label(  'rectification border' , 37   ,  2  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n    Label(  'out of roi'           , 38   ,  3  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n    Label(  'license plate'        , 39   , 255 ,     255 ,   255   ,      255 ,   'vehicle'             , 255         , 255    , False        , True         , (  0,  0,142)  ),\n    \n]           \n\n      \n\n# Function to get label information from pixel color\ndef get_label_by_color(color):\n    for label in labels:\n        if label.color == tuple(color):  # Compare the pixel color to the label color\n            return label\n    return None\n\n# Function to scale the polygons to the target resolution (1920x1080)\ndef scale_polygon(polygon, original_size=(512, 512), target_size=(1920, 1080)):\n    scale_x = target_size[0] / original_size[0]  # Scale factor for width\n    scale_y = target_size[1] / original_size[1]  # Scale factor for height\n\n    # Scale each point in the polygon\n    scaled_polygon = [[int(point[0] * scale_x), int(point[1] * scale_y)] for point in polygon]\n    \n    return scaled_polygon\n\n# Function to convert the segmented image into polygon-based format and prepare for CSV\ndef image_to_polygon_format(image_path, original_size=(512, 512), target_size=(1920, 1080)):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(f\"Image path '{image_path}' not found.\")\n    \n    segmented_image = cv2.imread(image_path)  # Load the segmented image\n    if segmented_image is None:\n        raise ValueError(f\"Failed to load image at '{image_path}'. Make sure the file is a valid image.\")\n\n    height, width, _ = segmented_image.shape\n\n    objects = []  # To hold the polygon data for each object\n\n    # Loop through all the labels\n    for label in labels:\n        if label.ignoreInEval:\n            continue  # Skip labels that should be ignored\n\n        # Convert the label color to a binary mask\n        mask = cv2.inRange(segmented_image, np.array(label.color), np.array(label.color))\n\n        # Find contours (polygons) in the binary mask\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            if len(contour) < 3:  # Skip small or invalid polygons\n                continue\n\n            # Simplify the contour to polygon format\n            polygon = contour.reshape(-1, 2).tolist()  # Flatten the contour to a list of points\n\n            # Scale the polygon to the target size\n            scaled_polygon = scale_polygon(polygon, original_size, target_size)\n            \n            # Create the object data for the current label and polygon\n            object_data = {\n                \"label\": label.name,\n                \"polygon\": scaled_polygon\n            }\n\n            # Append the object to the result\n            objects.append(object_data)\n\n    return objects\n\n# Function to save to the CSV format as requested\ndef save_to_csv(objects_dict, output_csv_path):\n    # Create a DataFrame with id and objects\n    data = [{\"id\": filename, \"objects\": json.dumps(objects)} for filename, objects in objects_dict.items()]\n    df = pd.DataFrame(data)\n    \n    # Save to CSV\n    df.to_csv(output_csv_path, index=False)\n\n# Main function to process multiple images and save the output CSV\ndef process_images(image_folder, output_csv_path):\n    if not os.path.exists(image_folder):\n        raise FileNotFoundError(f\"Image folder '{image_folder}' not found.\")\n    \n    objects_dict = {}\n\n    # Process each image and store the objects for each row ID\n    segmented_image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n\n    for image_path in segmented_image_paths:\n        # Get the filename without the extension\n        filename = os.path.splitext(os.path.basename(image_path))[0].replace('_gtFine_labelColors', '')\n        polygon_data = image_to_polygon_format(image_path,(512,512), (1920,1080))\n        objects_dict[filename] = polygon_data\n\n    # Save the results to CSV\n    save_to_csv(objects_dict, output_csv_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:53:54.314696Z","iopub.execute_input":"2024-10-10T15:53:54.315402Z","iopub.status.idle":"2024-10-10T15:53:54.358949Z","shell.execute_reply.started":"2024-10-10T15:53:54.315362Z","shell.execute_reply":"2024-10-10T15:53:54.35813Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_folder = \"newer_inference\"  # Same as output_dir in run_inference_and_store\noutput_csv_path = \"submission.csv\"\nprocess_images(image_folder, output_csv_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:54:18.208473Z","iopub.execute_input":"2024-10-10T15:54:18.209263Z","iopub.status.idle":"2024-10-10T15:54:21.511819Z","shell.execute_reply.started":"2024-10-10T15:54:18.209225Z","shell.execute_reply":"2024-10-10T15:54:21.511017Z"},"trusted":true},"outputs":[],"execution_count":null}]}